{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJLxeCZJ3dcjODcidhPotq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaurabhSRP/Stock-Price-Prediction-Projects/blob/main/Apple_Stock_Price_Prediction_using_AutoTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autots"
      ],
      "metadata": {
        "id": "ztCnH_84tuUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea86c56b-f375-4094-d91f-fe803bba23a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autots\n",
            "  Downloading AutoTS-0.5.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.* in /usr/local/lib/python3.7/dist-packages (from autots) (1.0.2)\n",
            "Requirement already satisfied: statsmodels>=0.10.* in /usr/local/lib/python3.7/dist-packages (from autots) (0.12.2)\n",
            "Requirement already satisfied: pandas>=0.25.* in /usr/local/lib/python3.7/dist-packages (from autots) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from autots) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.*->autots) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.*->autots) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.*->autots) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (1.7.3)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.10.*->autots) (0.5.2)\n",
            "Installing collected packages: autots\n",
            "Successfully installed autots-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy2_dbm6HTij",
        "outputId": "45605eeb-cf6f-4429-ae64-b779efba32fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Installing collected packages: requests, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed requests-2.28.1 yfinance-0.1.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autots import AutoTS"
      ],
      "metadata": {
        "id": "jWiEqilaGvZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import yfinance as yf\n",
        "import datetime \n",
        "from datetime import date, timedelta"
      ],
      "metadata": {
        "id": "IjoahOTxG1Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today=date.today()\n",
        "print(today)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t106c_bNHY4M",
        "outputId": "93c86096-7b53-4cd9-b471-fac47b80c524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_date=today.strftime(\"%Y-%m-%d\")\n",
        "start_date=date.today()-timedelta(days=365)"
      ],
      "metadata": {
        "id": "vP8T_kxdHd2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=yf.download('AAPL',start=start_date,end=end_date,progress=False)"
      ],
      "metadata": {
        "id": "9KvHCNeIHgPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "cf3movtoHiSR",
        "outputId": "bbd522c3-ffbe-457e-9fb9-7f668e00115a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Open        High  ...   Adj Close     Volume\n",
              "Date                                ...                       \n",
              "2021-09-27  145.470001  145.960007  ...  144.559952   74150700\n",
              "2021-09-28  143.250000  144.750000  ...  141.119217  108972300\n",
              "2021-09-29  142.470001  144.449997  ...  142.034119   74602000\n",
              "2021-09-30  143.660004  144.380005  ...  140.711517   89056700\n",
              "2021-10-01  141.899994  142.919998  ...  141.855103   94639600\n",
              "...                ...         ...  ...         ...        ...\n",
              "2022-09-19  149.309998  154.559998  ...  154.479996   81474200\n",
              "2022-09-20  153.399994  158.080002  ...  156.899994  107689800\n",
              "2022-09-21  157.339996  158.740005  ...  153.720001  101696800\n",
              "2022-09-22  152.380005  154.470001  ...  152.740005   86652500\n",
              "2022-09-23  151.190002  151.470001  ...  150.429993   95939200\n",
              "\n",
              "[251 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01093cb0-1ac0-40a6-ae87-bea5dc6272a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-09-27</th>\n",
              "      <td>145.470001</td>\n",
              "      <td>145.960007</td>\n",
              "      <td>143.820007</td>\n",
              "      <td>145.369995</td>\n",
              "      <td>144.559952</td>\n",
              "      <td>74150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-28</th>\n",
              "      <td>143.250000</td>\n",
              "      <td>144.750000</td>\n",
              "      <td>141.690002</td>\n",
              "      <td>141.910004</td>\n",
              "      <td>141.119217</td>\n",
              "      <td>108972300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-29</th>\n",
              "      <td>142.470001</td>\n",
              "      <td>144.449997</td>\n",
              "      <td>142.029999</td>\n",
              "      <td>142.830002</td>\n",
              "      <td>142.034119</td>\n",
              "      <td>74602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>143.660004</td>\n",
              "      <td>144.380005</td>\n",
              "      <td>141.279999</td>\n",
              "      <td>141.500000</td>\n",
              "      <td>140.711517</td>\n",
              "      <td>89056700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-01</th>\n",
              "      <td>141.899994</td>\n",
              "      <td>142.919998</td>\n",
              "      <td>139.110001</td>\n",
              "      <td>142.649994</td>\n",
              "      <td>141.855103</td>\n",
              "      <td>94639600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-19</th>\n",
              "      <td>149.309998</td>\n",
              "      <td>154.559998</td>\n",
              "      <td>149.100006</td>\n",
              "      <td>154.479996</td>\n",
              "      <td>154.479996</td>\n",
              "      <td>81474200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-20</th>\n",
              "      <td>153.399994</td>\n",
              "      <td>158.080002</td>\n",
              "      <td>153.080002</td>\n",
              "      <td>156.899994</td>\n",
              "      <td>156.899994</td>\n",
              "      <td>107689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-21</th>\n",
              "      <td>157.339996</td>\n",
              "      <td>158.740005</td>\n",
              "      <td>153.600006</td>\n",
              "      <td>153.720001</td>\n",
              "      <td>153.720001</td>\n",
              "      <td>101696800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-22</th>\n",
              "      <td>152.380005</td>\n",
              "      <td>154.470001</td>\n",
              "      <td>150.910004</td>\n",
              "      <td>152.740005</td>\n",
              "      <td>152.740005</td>\n",
              "      <td>86652500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-23</th>\n",
              "      <td>151.190002</td>\n",
              "      <td>151.470001</td>\n",
              "      <td>148.559998</td>\n",
              "      <td>150.429993</td>\n",
              "      <td>150.429993</td>\n",
              "      <td>95939200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>251 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01093cb0-1ac0-40a6-ae87-bea5dc6272a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01093cb0-1ac0-40a6-ae87-bea5dc6272a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01093cb0-1ac0-40a6-ae87-bea5dc6272a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Date\"]=data.index\n",
        "data=data[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\", \"Adj Close\", \"Volume\"]]\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "print(data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyLj6WJKHkBr",
        "outputId": "fd1981ba-586d-4eea-df3a-4bc78b0c6fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date        Open        High  ...       Close   Adj Close     Volume\n",
            "246 2022-09-19  149.309998  154.559998  ...  154.479996  154.479996   81474200\n",
            "247 2022-09-20  153.399994  158.080002  ...  156.899994  156.899994  107689800\n",
            "248 2022-09-21  157.339996  158.740005  ...  153.720001  153.720001  101696800\n",
            "249 2022-09-22  152.380005  154.470001  ...  152.740005  152.740005   86652500\n",
            "250 2022-09-23  151.190002  151.470001  ...  150.429993  150.429993   95939200\n",
            "\n",
            "[5 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "figure = go.Figure(data=[go.Candlestick(x=data[\"Date\"],\n",
        "                                        open=data[\"Open\"], high=data[\"High\"],\n",
        "                                        low=data[\"Low\"], close=data[\"Close\"])])\n",
        "figure.update_layout(title = \"Apple Stock Price Analysis\", xaxis_rangeslider_visible=False)\n",
        "figure.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cPWUKNAHHmLj",
        "outputId": "a116b5b0-c698-4682-a298-89d25615fafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"35211105-70b1-4890-905c-626f2cdf7445\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"35211105-70b1-4890-905c-626f2cdf7445\")) {                    Plotly.newPlot(                        \"35211105-70b1-4890-905c-626f2cdf7445\",                        [{\"close\":[145.3699951171875,141.91000366210938,142.8300018310547,141.5,142.64999389648438,139.13999938964844,141.11000061035156,142.0,143.2899932861328,142.89999389648438,142.80999755859375,141.50999450683594,140.91000366210938,143.75999450683594,144.83999633789062,146.5500030517578,148.75999450683594,149.25999450683594,149.47999572753906,148.69000244140625,148.63999938964844,149.32000732421875,148.85000610351562,152.57000732421875,149.8000030517578,148.9600067138672,150.02000427246094,151.49000549316406,150.9600067138672,151.27999877929688,150.44000244140625,150.80999755859375,147.9199981689453,147.8699951171875,149.99000549316406,150.0,151.0,153.49000549316406,157.8699951171875,160.5500030517578,161.02000427246094,161.41000366210938,161.94000244140625,156.80999755859375,160.24000549316406,165.3000030517578,164.77000427246094,163.75999450683594,161.83999633789062,165.32000732421875,171.17999267578125,175.0800018310547,174.55999755859375,179.4499969482422,175.74000549316406,174.3300018310547,179.3000030517578,172.25999450683594,171.13999938964844,169.75,172.99000549316406,175.63999938964844,176.27999877929688,180.3300018310547,179.2899932861328,179.3800048828125,178.1999969482422,177.57000732421875,182.00999450683594,179.6999969482422,174.9199981689453,172.0,172.1699981689453,172.19000244140625,175.0800018310547,175.52999877929688,172.19000244140625,173.07000732421875,169.8000030517578,166.22999572753906,164.50999450683594,162.41000366210938,161.6199951171875,159.77999877929688,159.69000244140625,159.22000122070312,170.3300018310547,174.77999877929688,174.61000061035156,175.83999633789062,172.89999389648438,172.38999938964844,171.66000366210938,174.8300018310547,176.27999877929688,172.1199951171875,168.63999938964844,168.8800048828125,172.7899932861328,172.5500030517578,168.8800048828125,167.3000030517578,164.32000732421875,160.07000732421875,162.74000549316406,164.85000610351562,165.1199951171875,163.1999969482422,166.55999755859375,166.22999572753906,163.1699981689453,159.3000030517578,157.44000244140625,162.9499969482422,158.52000427246094,154.72999572753906,150.6199951171875,155.08999633789062,159.58999633789062,160.6199951171875,163.97999572753906,165.3800048828125,168.82000732421875,170.2100067138672,174.07000732421875,174.72000122070312,175.60000610351562,178.9600067138672,177.77000427246094,174.61000061035156,174.30999755859375,178.44000244140625,175.05999755859375,171.8300018310547,172.13999938964844,170.08999633789062,165.75,167.66000366210938,170.39999389648438,165.2899932861328,165.07000732421875,167.39999389648438,167.22999572753906,166.4199981689453,161.7899932861328,162.8800048828125,156.8000030517578,156.57000732421875,163.63999938964844,157.64999389648438,157.9600067138672,159.47999572753906,166.02000427246094,156.77000427246094,157.27999877929688,152.05999755859375,154.50999450683594,146.5,142.55999755859375,147.11000061035156,145.5399932861328,149.24000549316406,140.82000732421875,137.35000610351562,137.58999633789062,143.11000061035156,140.36000061035156,140.52000427246094,143.77999877929688,149.63999938964844,148.83999633789062,148.7100067138672,151.2100067138672,145.3800048828125,146.13999938964844,148.7100067138672,147.9600067138672,142.63999938964844,137.1300048828125,131.8800048828125,132.75999450683594,135.42999267578125,130.05999755859375,131.55999755859375,135.8699951171875,135.35000610351562,138.27000427246094,141.66000366210938,141.66000366210938,137.44000244140625,139.22999572753906,136.72000122070312,138.92999267578125,141.55999755859375,142.9199981689453,146.35000610351562,147.0399932861328,144.8699951171875,145.86000061035156,145.49000549316406,148.47000122070312,150.1699981689453,147.07000732421875,151.0,153.0399932861328,155.35000610351562,154.08999633789062,152.9499969482422,151.60000610351562,156.7899932861328,157.35000610351562,162.50999450683594,161.50999450683594,160.00999450683594,166.1300048828125,165.80999755859375,165.35000610351562,164.8699951171875,164.9199981689453,169.24000549316406,168.49000549316406,172.10000610351562,173.19000244140625,173.02999877929688,174.5500030517578,174.14999389648438,171.52000427246094,167.57000732421875,167.22999572753906,167.52999877929688,170.02999877929688,163.6199951171875,161.3800048828125,158.91000366210938,157.22000122070312,157.9600067138672,155.80999755859375,154.52999877929688,155.9600067138672,154.4600067138672,157.3699951171875,163.42999267578125,153.83999633789062,155.30999755859375,152.3699951171875,150.6999969482422,154.47999572753906,156.89999389648438,153.72000122070312,152.74000549316406,150.42999267578125],\"high\":[145.9600067138672,144.75,144.4499969482422,144.3800048828125,142.9199981689453,142.2100067138672,142.24000549316406,142.14999389648438,144.22000122070312,144.17999267578125,144.80999755859375,143.25,141.39999389648438,143.8800048828125,144.89999389648438,146.83999633789062,149.1699981689453,149.75,149.63999938964844,150.17999267578125,149.3699951171875,150.83999633789062,149.72999572753906,153.1699981689453,149.94000244140625,149.6999969482422,151.57000732421875,151.97000122070312,152.42999267578125,152.1999969482422,151.57000732421875,151.42999267578125,150.1300048828125,149.42999267578125,150.39999389648438,151.8800048828125,151.49000549316406,155.0,158.6699981689453,161.02000427246094,165.6999969482422,161.8000030517578,162.13999938964844,160.4499969482422,161.19000244140625,165.52000427246094,170.3000030517578,164.1999969482422,164.9600067138672,167.8800048828125,171.5800018310547,175.9600067138672,176.75,179.6300048828125,182.1300048828125,177.74000549316406,179.5,181.13999938964844,173.47000122070312,170.5800018310547,173.1999969482422,175.86000061035156,176.85000610351562,180.4199981689453,181.3300018310547,180.6300048828125,180.57000732421875,179.22999572753906,182.8800048828125,182.94000244140625,180.1699981689453,175.3000030517578,174.13999938964844,172.5,175.17999267578125,177.17999267578125,176.6199951171875,173.77999877929688,172.5399932861328,171.0800018310547,169.67999267578125,166.3300018310547,162.3000030517578,162.75999450683594,164.38999938964844,163.83999633789062,170.35000610351562,175.0,174.83999633789062,175.8800048828125,176.24000549316406,174.10000610351562,173.9499969482422,175.35000610351562,176.64999389648438,175.47999572753906,173.0800018310547,169.5800018310547,172.9499969482422,173.33999633789062,171.91000366210938,170.5399932861328,166.69000244140625,166.14999389648438,162.85000610351562,165.1199951171875,165.4199981689453,166.60000610351562,167.36000061035156,168.91000366210938,165.5500030517578,165.02000427246094,162.8800048828125,163.41000366210938,160.38999938964844,159.27999877929688,154.1199951171875,155.57000732421875,160.0,161.0,164.47999572753906,166.35000610351562,169.4199981689453,172.63999938964844,174.13999938964844,175.27999877929688,175.72999572753906,179.00999450683594,179.61000061035156,178.02999877929688,174.8800048828125,178.49000549316406,178.3000030517578,173.6300048828125,173.36000061035156,171.77999877929688,169.02999877929688,169.8699951171875,171.0399932861328,171.27000427246094,166.60000610351562,167.82000732421875,168.8800048828125,171.52999877929688,167.8699951171875,163.1699981689453,162.33999633789062,159.7899932861328,164.52000427246094,166.1999969482422,158.22999572753906,160.7100067138672,166.47999572753906,164.0800018310547,159.44000244140625,155.8300018310547,156.74000549316406,155.4499969482422,146.1999969482422,148.10000610351562,147.52000427246094,149.77000427246094,147.36000061035156,141.66000366210938,140.6999969482422,143.25999450683594,141.97000122070312,141.7899932861328,144.33999633789062,149.67999267578125,150.66000366210938,151.74000549316406,151.27000427246094,147.97000122070312,148.57000732421875,149.0,149.8699951171875,147.9499969482422,140.75999450683594,135.1999969482422,133.88999938964844,137.33999633789062,132.38999938964844,133.0800018310547,137.05999755859375,137.75999450683594,138.58999633789062,141.91000366210938,143.49000549316406,143.4199981689453,140.6699981689453,138.3699951171875,139.0399932861328,141.61000061035156,144.1199951171875,146.5500030517578,147.5500030517578,146.63999938964844,148.4499969482422,146.4499969482422,148.9499969482422,150.86000061035156,151.57000732421875,151.22999572753906,153.72000122070312,155.57000732421875,156.27999877929688,155.0399932861328,153.08999633789062,157.3300018310547,157.63999938964844,163.6300048828125,163.58999633789062,162.41000366210938,166.58999633789062,167.19000244140625,165.85000610351562,167.80999755859375,165.82000732421875,169.33999633789062,170.99000549316406,172.1699981689453,173.38999938964844,173.7100067138672,176.14999389648438,174.89999389648438,173.74000549316406,169.86000061035156,168.7100067138672,168.11000061035156,170.13999938964844,171.0500030517578,162.89999389648438,162.55999755859375,160.5800018310547,158.4199981689453,160.36000061035156,157.08999633789062,156.6699981689453,156.36000061035156,157.82000732421875,164.25999450683594,160.5399932861328,157.10000610351562,155.24000549316406,151.35000610351562,154.55999755859375,158.0800018310547,158.74000549316406,154.47000122070312,151.47000122070312],\"low\":[143.82000732421875,141.69000244140625,142.02999877929688,141.27999877929688,139.11000061035156,138.27000427246094,139.36000061035156,138.3699951171875,142.72000122070312,142.55999755859375,141.80999755859375,141.0399932861328,139.1999969482422,141.50999450683594,143.50999450683594,143.16000366210938,146.5500030517578,148.1199951171875,147.8699951171875,148.63999938964844,147.6199951171875,149.00999450683594,148.49000549316406,149.72000122070312,146.41000366210938,147.8000030517578,148.64999389648438,149.82000732421875,150.63999938964844,150.05999755859375,150.16000366210938,150.05999755859375,147.85000610351562,147.67999267578125,147.47999572753906,149.42999267578125,149.33999633789062,150.99000549316406,153.0500030517578,156.52999877929688,161.0,159.05999755859375,159.63999938964844,156.36000061035156,158.7899932861328,159.9199981689453,164.52999877929688,157.8000030517578,159.72000122070312,164.27999877929688,168.33999633789062,170.6999969482422,173.9199981689453,174.69000244140625,175.52999877929688,172.2100067138672,172.30999755859375,170.75,169.69000244140625,167.4600067138672,169.1199951171875,172.14999389648438,175.27000427246094,177.07000732421875,178.52999877929688,178.13999938964844,178.08999633789062,177.25999450683594,177.7100067138672,179.1199951171875,174.63999938964844,171.63999938964844,171.02999877929688,168.1699981689453,170.82000732421875,174.82000732421875,171.7899932861328,171.08999633789062,169.41000366210938,165.94000244140625,164.17999267578125,162.3000030517578,154.6999969482422,157.02000427246094,157.82000732421875,158.27999877929688,162.8000030517578,169.50999450683594,172.30999755859375,173.3300018310547,172.1199951171875,170.67999267578125,170.9499969482422,171.42999267578125,174.89999389648438,171.5500030517578,168.0399932861328,166.55999755859375,170.25,170.0500030517578,168.47000122070312,166.19000244140625,162.14999389648438,159.75,152.0,160.8699951171875,162.42999267578125,161.97000122070312,162.9499969482422,165.5500030517578,162.10000610351562,159.0399932861328,155.8000030517578,159.41000366210938,155.97999572753906,154.5,150.10000610351562,150.3800048828125,154.4600067138672,157.6300048828125,159.75999450683594,163.00999450683594,164.91000366210938,167.64999389648438,170.2100067138672,172.75,172.0,176.33999633789062,176.6999969482422,174.39999389648438,171.94000244140625,174.44000244140625,174.4199981689453,170.1300048828125,169.85000610351562,169.1999969482422,165.5,166.63999938964844,166.77000427246094,165.0399932861328,163.57000732421875,163.91000366210938,166.10000610351562,165.91000366210938,161.5,158.4600067138672,156.72000122070312,155.3800048828125,158.92999267578125,157.25,153.27000427246094,156.32000732421875,159.25999450683594,154.9499969482422,154.17999267578125,151.49000549316406,152.92999267578125,145.80999755859375,138.8000030517578,143.11000061035156,144.17999267578125,146.67999267578125,139.89999389648438,136.60000610351562,132.61000061035156,137.64999389648438,137.3300018310547,138.33999633789062,137.13999938964844,145.25999450683594,146.83999633789062,147.67999267578125,146.86000061035156,144.4600067138672,144.89999389648438,144.10000610351562,147.4600067138672,142.52999877929688,137.05999755859375,131.44000244140625,131.47999572753906,132.16000366210938,129.0399932861328,129.80999755859375,133.32000732421875,133.91000366210938,135.6300048828125,139.77000427246094,140.97000122070312,137.32000732421875,136.6699981689453,133.77000427246094,135.66000366210938,136.92999267578125,141.0800018310547,143.27999877929688,145.0,143.77999877929688,145.0500030517578,142.1199951171875,143.25,148.1999969482422,146.6999969482422,146.91000366210938,150.3699951171875,151.94000244140625,153.41000366210938,152.27999877929688,150.8000030517578,152.16000366210938,154.41000366210938,159.5,160.88999938964844,159.6300048828125,160.75,164.42999267578125,163.0,164.1999969482422,163.25,166.89999389648438,168.19000244140625,169.39999389648438,171.35000610351562,171.66000366210938,172.57000732421875,173.1199951171875,171.30999755859375,167.13999938964844,166.64999389648438,166.25,168.35000610351562,163.55999755859375,159.82000732421875,157.72000122070312,157.13999938964844,154.6699981689453,154.97000122070312,153.69000244140625,153.61000061035156,152.67999267578125,154.75,159.3000030517578,153.3699951171875,153.61000061035156,151.3800048828125,148.3699951171875,149.10000610351562,153.0800018310547,153.60000610351562,150.91000366210938,148.55999755859375],\"open\":[145.47000122070312,143.25,142.47000122070312,143.66000366210938,141.89999389648438,141.75999450683594,139.49000549316406,139.47000122070312,143.05999755859375,144.02999877929688,142.27000427246094,143.22999572753906,141.24000549316406,142.11000061035156,143.77000427246094,143.4499969482422,147.00999450683594,148.6999969482422,148.80999755859375,149.69000244140625,148.67999267578125,149.3300018310547,149.36000061035156,149.82000732421875,147.22000122070312,148.99000549316406,148.66000366210938,150.38999938964844,151.5800018310547,151.88999938964844,151.41000366210938,150.1999969482422,150.02000427246094,148.9600067138672,148.42999267578125,150.3699951171875,149.94000244140625,151.0,153.7100067138672,157.64999389648438,161.67999267578125,161.1199951171875,160.75,159.57000732421875,159.3699951171875,159.99000549316406,167.47999572753906,158.74000549316406,164.02000427246094,164.2899932861328,169.0800018310547,172.1300048828125,174.91000366210938,175.2100067138672,181.1199951171875,175.25,175.11000061035156,179.27999877929688,169.92999267578125,168.27999877929688,171.55999755859375,173.0399932861328,175.85000610351562,177.08999633789062,180.16000366210938,179.3300018310547,179.47000122070312,178.08999633789062,177.8300018310547,182.6300048828125,179.61000061035156,172.6999969482422,172.88999938964844,169.0800018310547,172.32000732421875,176.1199951171875,175.77999877929688,171.33999633789062,171.50999450683594,170.0,166.97999572753906,164.4199981689453,160.02000427246094,158.97999572753906,163.5,162.4499969482422,165.7100067138672,170.16000366210938,174.00999450683594,174.75,174.47999572753906,171.67999267578125,172.86000061035156,171.72999572753906,176.0500030517578,174.13999938964844,172.3300018310547,167.3699951171875,170.97000122070312,171.85000610351562,171.02999877929688,169.82000732421875,164.97999572753906,165.5399932861328,152.5800018310547,163.83999633789062,163.05999755859375,164.6999969482422,164.38999938964844,168.47000122070312,164.49000549316406,163.36000061035156,158.82000732421875,161.47999572753906,160.1999969482422,158.92999267578125,151.4499969482422,150.89999389648438,157.0500030517578,158.61000061035156,160.50999450683594,163.50999450683594,165.50999450683594,167.99000549316406,171.05999755859375,173.8800048828125,172.1699981689453,176.69000244140625,178.5500030517578,177.83999633789062,174.02999877929688,174.57000732421875,177.5,172.36000061035156,171.16000366210938,171.77999877929688,168.7100067138672,168.02000427246094,167.38999938964844,170.6199951171875,163.9199981689453,165.02000427246094,168.75999450683594,168.91000366210938,166.4600067138672,161.1199951171875,162.25,155.91000366210938,159.25,161.83999633789062,156.7100067138672,158.14999389648438,159.6699981689453,163.85000610351562,156.00999450683594,154.92999267578125,155.52000427246094,153.5,142.77000427246094,144.58999633789062,145.5500030517578,148.86000061035156,146.85000610351562,139.8800048828125,139.08999633789062,137.7899932861328,140.80999755859375,138.42999267578125,137.38999938964844,145.38999938964844,149.07000732421875,149.89999389648438,147.8300018310547,146.89999389648438,147.02999877929688,144.35000610351562,148.5800018310547,147.0800018310547,140.27999877929688,132.8699951171875,133.1300048828125,134.2899932861328,132.0800018310547,130.07000732421875,133.4199981689453,134.7899932861328,136.82000732421875,139.89999389648438,142.6999969482422,142.1300048828125,137.4600067138672,137.25,136.0399932861328,137.77000427246094,141.35000610351562,143.2899932861328,145.25999450683594,145.6699981689453,145.75999450683594,142.99000549316406,144.0800018310547,149.77999877929688,150.74000549316406,147.9199981689453,151.1199951171875,154.5,155.38999938964844,154.00999450683594,152.25999450683594,152.5800018310547,156.97999572753906,161.24000549316406,161.00999450683594,160.10000610351562,160.83999633789062,166.00999450683594,163.2100067138672,166.3699951171875,164.02000427246094,167.67999267578125,170.05999755859375,169.82000732421875,171.52000427246094,172.77999877929688,172.77000427246094,173.75,173.02999877929688,169.69000244140625,167.0800018310547,167.32000732421875,168.77999877929688,170.57000732421875,161.14999389648438,162.1300048828125,160.30999755859375,156.63999938964844,159.75,156.47000122070312,154.82000732421875,154.63999938964844,155.47000122070312,159.58999633789062,159.89999389648438,154.7899932861328,154.64999389648438,151.2100067138672,149.30999755859375,153.39999389648438,157.33999633789062,152.3800048828125,151.19000244140625],\"x\":[\"2021-09-27T00:00:00\",\"2021-09-28T00:00:00\",\"2021-09-29T00:00:00\",\"2021-09-30T00:00:00\",\"2021-10-01T00:00:00\",\"2021-10-04T00:00:00\",\"2021-10-05T00:00:00\",\"2021-10-06T00:00:00\",\"2021-10-07T00:00:00\",\"2021-10-08T00:00:00\",\"2021-10-11T00:00:00\",\"2021-10-12T00:00:00\",\"2021-10-13T00:00:00\",\"2021-10-14T00:00:00\",\"2021-10-15T00:00:00\",\"2021-10-18T00:00:00\",\"2021-10-19T00:00:00\",\"2021-10-20T00:00:00\",\"2021-10-21T00:00:00\",\"2021-10-22T00:00:00\",\"2021-10-25T00:00:00\",\"2021-10-26T00:00:00\",\"2021-10-27T00:00:00\",\"2021-10-28T00:00:00\",\"2021-10-29T00:00:00\",\"2021-11-01T00:00:00\",\"2021-11-02T00:00:00\",\"2021-11-03T00:00:00\",\"2021-11-04T00:00:00\",\"2021-11-05T00:00:00\",\"2021-11-08T00:00:00\",\"2021-11-09T00:00:00\",\"2021-11-10T00:00:00\",\"2021-11-11T00:00:00\",\"2021-11-12T00:00:00\",\"2021-11-15T00:00:00\",\"2021-11-16T00:00:00\",\"2021-11-17T00:00:00\",\"2021-11-18T00:00:00\",\"2021-11-19T00:00:00\",\"2021-11-22T00:00:00\",\"2021-11-23T00:00:00\",\"2021-11-24T00:00:00\",\"2021-11-26T00:00:00\",\"2021-11-29T00:00:00\",\"2021-11-30T00:00:00\",\"2021-12-01T00:00:00\",\"2021-12-02T00:00:00\",\"2021-12-03T00:00:00\",\"2021-12-06T00:00:00\",\"2021-12-07T00:00:00\",\"2021-12-08T00:00:00\",\"2021-12-09T00:00:00\",\"2021-12-10T00:00:00\",\"2021-12-13T00:00:00\",\"2021-12-14T00:00:00\",\"2021-12-15T00:00:00\",\"2021-12-16T00:00:00\",\"2021-12-17T00:00:00\",\"2021-12-20T00:00:00\",\"2021-12-21T00:00:00\",\"2021-12-22T00:00:00\",\"2021-12-23T00:00:00\",\"2021-12-27T00:00:00\",\"2021-12-28T00:00:00\",\"2021-12-29T00:00:00\",\"2021-12-30T00:00:00\",\"2021-12-31T00:00:00\",\"2022-01-03T00:00:00\",\"2022-01-04T00:00:00\",\"2022-01-05T00:00:00\",\"2022-01-06T00:00:00\",\"2022-01-07T00:00:00\",\"2022-01-10T00:00:00\",\"2022-01-11T00:00:00\",\"2022-01-12T00:00:00\",\"2022-01-13T00:00:00\",\"2022-01-14T00:00:00\",\"2022-01-18T00:00:00\",\"2022-01-19T00:00:00\",\"2022-01-20T00:00:00\",\"2022-01-21T00:00:00\",\"2022-01-24T00:00:00\",\"2022-01-25T00:00:00\",\"2022-01-26T00:00:00\",\"2022-01-27T00:00:00\",\"2022-01-28T00:00:00\",\"2022-01-31T00:00:00\",\"2022-02-01T00:00:00\",\"2022-02-02T00:00:00\",\"2022-02-03T00:00:00\",\"2022-02-04T00:00:00\",\"2022-02-07T00:00:00\",\"2022-02-08T00:00:00\",\"2022-02-09T00:00:00\",\"2022-02-10T00:00:00\",\"2022-02-11T00:00:00\",\"2022-02-14T00:00:00\",\"2022-02-15T00:00:00\",\"2022-02-16T00:00:00\",\"2022-02-17T00:00:00\",\"2022-02-18T00:00:00\",\"2022-02-22T00:00:00\",\"2022-02-23T00:00:00\",\"2022-02-24T00:00:00\",\"2022-02-25T00:00:00\",\"2022-02-28T00:00:00\",\"2022-03-01T00:00:00\",\"2022-03-02T00:00:00\",\"2022-03-03T00:00:00\",\"2022-03-04T00:00:00\",\"2022-03-07T00:00:00\",\"2022-03-08T00:00:00\",\"2022-03-09T00:00:00\",\"2022-03-10T00:00:00\",\"2022-03-11T00:00:00\",\"2022-03-14T00:00:00\",\"2022-03-15T00:00:00\",\"2022-03-16T00:00:00\",\"2022-03-17T00:00:00\",\"2022-03-18T00:00:00\",\"2022-03-21T00:00:00\",\"2022-03-22T00:00:00\",\"2022-03-23T00:00:00\",\"2022-03-24T00:00:00\",\"2022-03-25T00:00:00\",\"2022-03-28T00:00:00\",\"2022-03-29T00:00:00\",\"2022-03-30T00:00:00\",\"2022-03-31T00:00:00\",\"2022-04-01T00:00:00\",\"2022-04-04T00:00:00\",\"2022-04-05T00:00:00\",\"2022-04-06T00:00:00\",\"2022-04-07T00:00:00\",\"2022-04-08T00:00:00\",\"2022-04-11T00:00:00\",\"2022-04-12T00:00:00\",\"2022-04-13T00:00:00\",\"2022-04-14T00:00:00\",\"2022-04-18T00:00:00\",\"2022-04-19T00:00:00\",\"2022-04-20T00:00:00\",\"2022-04-21T00:00:00\",\"2022-04-22T00:00:00\",\"2022-04-25T00:00:00\",\"2022-04-26T00:00:00\",\"2022-04-27T00:00:00\",\"2022-04-28T00:00:00\",\"2022-04-29T00:00:00\",\"2022-05-02T00:00:00\",\"2022-05-03T00:00:00\",\"2022-05-04T00:00:00\",\"2022-05-05T00:00:00\",\"2022-05-06T00:00:00\",\"2022-05-09T00:00:00\",\"2022-05-10T00:00:00\",\"2022-05-11T00:00:00\",\"2022-05-12T00:00:00\",\"2022-05-13T00:00:00\",\"2022-05-16T00:00:00\",\"2022-05-17T00:00:00\",\"2022-05-18T00:00:00\",\"2022-05-19T00:00:00\",\"2022-05-20T00:00:00\",\"2022-05-23T00:00:00\",\"2022-05-24T00:00:00\",\"2022-05-25T00:00:00\",\"2022-05-26T00:00:00\",\"2022-05-27T00:00:00\",\"2022-05-31T00:00:00\",\"2022-06-01T00:00:00\",\"2022-06-02T00:00:00\",\"2022-06-03T00:00:00\",\"2022-06-06T00:00:00\",\"2022-06-07T00:00:00\",\"2022-06-08T00:00:00\",\"2022-06-09T00:00:00\",\"2022-06-10T00:00:00\",\"2022-06-13T00:00:00\",\"2022-06-14T00:00:00\",\"2022-06-15T00:00:00\",\"2022-06-16T00:00:00\",\"2022-06-17T00:00:00\",\"2022-06-21T00:00:00\",\"2022-06-22T00:00:00\",\"2022-06-23T00:00:00\",\"2022-06-24T00:00:00\",\"2022-06-27T00:00:00\",\"2022-06-28T00:00:00\",\"2022-06-29T00:00:00\",\"2022-06-30T00:00:00\",\"2022-07-01T00:00:00\",\"2022-07-05T00:00:00\",\"2022-07-06T00:00:00\",\"2022-07-07T00:00:00\",\"2022-07-08T00:00:00\",\"2022-07-11T00:00:00\",\"2022-07-12T00:00:00\",\"2022-07-13T00:00:00\",\"2022-07-14T00:00:00\",\"2022-07-15T00:00:00\",\"2022-07-18T00:00:00\",\"2022-07-19T00:00:00\",\"2022-07-20T00:00:00\",\"2022-07-21T00:00:00\",\"2022-07-22T00:00:00\",\"2022-07-25T00:00:00\",\"2022-07-26T00:00:00\",\"2022-07-27T00:00:00\",\"2022-07-28T00:00:00\",\"2022-07-29T00:00:00\",\"2022-08-01T00:00:00\",\"2022-08-02T00:00:00\",\"2022-08-03T00:00:00\",\"2022-08-04T00:00:00\",\"2022-08-05T00:00:00\",\"2022-08-08T00:00:00\",\"2022-08-09T00:00:00\",\"2022-08-10T00:00:00\",\"2022-08-11T00:00:00\",\"2022-08-12T00:00:00\",\"2022-08-15T00:00:00\",\"2022-08-16T00:00:00\",\"2022-08-17T00:00:00\",\"2022-08-18T00:00:00\",\"2022-08-19T00:00:00\",\"2022-08-22T00:00:00\",\"2022-08-23T00:00:00\",\"2022-08-24T00:00:00\",\"2022-08-25T00:00:00\",\"2022-08-26T00:00:00\",\"2022-08-29T00:00:00\",\"2022-08-30T00:00:00\",\"2022-08-31T00:00:00\",\"2022-09-01T00:00:00\",\"2022-09-02T00:00:00\",\"2022-09-06T00:00:00\",\"2022-09-07T00:00:00\",\"2022-09-08T00:00:00\",\"2022-09-09T00:00:00\",\"2022-09-12T00:00:00\",\"2022-09-13T00:00:00\",\"2022-09-14T00:00:00\",\"2022-09-15T00:00:00\",\"2022-09-16T00:00:00\",\"2022-09-19T00:00:00\",\"2022-09-20T00:00:00\",\"2022-09-21T00:00:00\",\"2022-09-22T00:00:00\",\"2022-09-23T00:00:00\"],\"type\":\"candlestick\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"rangeslider\":{\"visible\":false}},\"title\":{\"text\":\"Apple Stock Price Analysis\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('35211105-70b1-4890-905c-626f2cdf7445');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=data[[\"Date\",\"Close\"]]\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRXLsY3yHopG",
        "outputId": "2ec8a4cc-b677-4625-c26e-dda903d060c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date       Close\n",
            "0 2021-09-27  145.369995\n",
            "1 2021-09-28  141.910004\n",
            "2 2021-09-29  142.830002\n",
            "3 2021-09-30  141.500000\n",
            "4 2021-10-01  142.649994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(df[\"Date\"],df[\"Close\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "LG-1sdy4Hqln",
        "outputId": "f7eb18e3-aeae-4460-dbb8-42d35896ac6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc02bdce150>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoTS(forecast_length=10, frequency='infer', \n",
        "               ensemble='simple', drop_data_older_than_periods=200)\n",
        "model = model.fit(data, date_col='Date', value_col='Close', id_col=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFFAODIrHszj",
        "outputId": "8a943be2-48fb-41a4-f2df-4bc7313ecce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred frequency is: B\n",
            "Old data dropped by `drop_data_older_than_periods`.\n",
            "Model Number: 1 with model ARIMA in generation 0 of 10\n",
            "Model Number: 2 with model ARIMA in generation 0 of 10\n",
            "Model Number: 3 with model ARIMA in generation 0 of 10\n",
            "Model Number: 4 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 5 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 6 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 8 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 9 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 10 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "6/6 [==============================] - 7s 6ms/step - loss: 0.3882\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3859\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3838\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3838\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3807\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3799\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3786\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3729\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3678\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3665\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3637\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3592\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3582\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3499\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3454\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3427\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3393\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3345\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3375\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3271\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3309\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3206\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3144\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3120\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3003\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2994\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3029\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2941\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2948\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2945\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2831\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2661\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2792\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2706\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2597\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2595\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2585\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2617\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2624\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2504\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2622\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2633\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2485\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2430\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2395\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2312\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2332\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2302\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2388\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2319\n",
            "Model Number: 11 with model ETS in generation 0 of 10\n",
            "Model Number: 12 with model ETS in generation 0 of 10\n",
            "Model Number: 13 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('shapes (10,56) and (58,) not aligned: 56 (dim 1) != 58 (dim 0)') in model 13: GLM\n",
            "Model Number: 14 with model GLM in generation 0 of 10\n",
            "Model Number: 15 with model GLS in generation 0 of 10\n",
            "Model Number: 16 with model GLS in generation 0 of 10\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 17: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 18: GluonTS\n",
            "Model Number: 19 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 19: GluonTS\n",
            "Model Number: 20 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 20: GluonTS\n",
            "Model Number: 21 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 21: GluonTS\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 24 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 25 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 26 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 27 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 28 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 29 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 30 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 31 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 32 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 32: VAR\n",
            "Model Number: 33 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 33: VAR\n",
            "Model Number: 34 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 34: VECM\n",
            "Model Number: 35 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 35: VECM\n",
            "Model Number: 36 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 37 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 38 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ql7yfx9t.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/7m8e6kh_.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=50116', 'data', 'file=/tmp/tmpc_zyl9m1/ql7yfx9t.json', 'init=/tmp/tmpc_zyl9m1/7m8e6kh_.json', 'output', 'file=/tmp/tmpofkghd6_/prophet_model-20220925144938.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "14:49:38 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:49:39 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 39 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 39: GluonTS\n",
            "Model Number: 40 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 41 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 41: MultivariateRegression\n",
            "Model Number: 42 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 42: DatepartRegression\n",
            "Model Number: 43 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 44 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 45 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 46 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 47 with model ETS in generation 0 of 10\n",
            "Model Number: 48 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 48: VECM\n",
            "Model Number: 49 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 49: ARDL\n",
            "Model Number: 50 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 51 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 52 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 53 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 54 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 55 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 56 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/22x7cfu5.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/4z_uv39s.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=1850', 'data', 'file=/tmp/tmpc_zyl9m1/22x7cfu5.json', 'init=/tmp/tmpc_zyl9m1/4z_uv39s.json', 'output', 'file=/tmp/tmpneszfhv6/prophet_model-20220925144943.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "14:49:43 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 57 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:49:44 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 58 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 59 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('X has 56 features, but RandomForestRegressor is expecting 58 features as input.') in model 59: DatepartRegression\n",
            "Model Number: 60 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning:\n",
            "\n",
            "The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- weekdayofmonth_1\n",
            "- weekdayofmonth_5\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 61 with model Theta in generation 0 of 10\n",
            "Model Number: 62 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 62: UnivariateRegression\n",
            "Model Number: 63 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 63: ARCH\n",
            "Model Number: 64 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 65 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 65: LastValueNaive\n",
            "Model Number: 66 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 67 with model GLS in generation 0 of 10\n",
            "Model Number: 68 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 69 with model GLM in generation 0 of 10\n",
            "Model Number: 70 with model ETS in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/wdgpcxmr.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ej76jfti.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=77922', 'data', 'file=/tmp/tmpc_zyl9m1/wdgpcxmr.json', 'init=/tmp/tmpc_zyl9m1/ej76jfti.json', 'output', 'file=/tmp/tmpco33h5q9/prophet_model-20220925144946.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:49:46 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 71 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:49:46 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 72 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 72: GluonTS\n",
            "Model Number: 73 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 73: UnobservedComponents\n",
            "Model Number: 74 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 74: VAR\n",
            "Model Number: 75 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 75: VECM\n",
            "Model Number: 76 with model ARIMA in generation 0 of 10\n",
            "Model Number: 77 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 78 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 78: DatepartRegression\n",
            "Model Number: 79 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 79: UnivariateRegression\n",
            "Model Number: 80 with model MultivariateRegression in generation 0 of 10\n",
            "Model Number: 81 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 82 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 83 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type=='User' but no future_regressor supplied\") in model 83: SectionalMotif\n",
            "Model Number: 84 with model NVAR in generation 0 of 10\n",
            "Model Number: 85 with model Theta in generation 0 of 10\n",
            "Model Number: 86 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 86: ARDL\n",
            "Model Number: 87 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 87: ARCH\n",
            "Model Number: 88 with model Theta in generation 0 of 10\n",
            "Model Number: 89 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 90 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 90: ARCH\n",
            "Model Number: 91 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 92 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 93 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 94 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 95 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 96 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 97 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 97: ARCH\n",
            "Model Number: 98 with model GLM in generation 0 of 10\n",
            "Model Number: 99 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 99: GluonTS\n",
            "Model Number: 100 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 100: VAR\n",
            "Model Number: 101 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 101: ARDL\n",
            "Model Number: 102 with model GLS in generation 0 of 10\n",
            "Model Number: 103 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 104 with model NVAR in generation 0 of 10\n",
            "Model Number: 105 with model GLM in generation 0 of 10\n",
            "Model Number: 106 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 106: DatepartRegression\n",
            "Model Number: 107 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (35)') in model 107: SectionalMotif\n",
            "Model Number: 108 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 109 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 110 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 111 with model Theta in generation 0 of 10\n",
            "Model Number: 112 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 113 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 114 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 115 with model ETS in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/polyint.py:545: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/polyint.py:546: RuntimeWarning:\n",
            "\n",
            "overflow encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/polyint.py:643: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 116 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 116: WindowRegression\n",
            "Model Number: 117 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning:\n",
            "\n",
            "Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 118 with model Theta in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 118: Theta\n",
            "Model Number: 119 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 120 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 121 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 121: MultivariateRegression\n",
            "Model Number: 122 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 123 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 124 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 125 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 126 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 126: DatepartRegression\n",
            "Model Number: 127 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 127: GluonTS\n",
            "Model Number: 128 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 128: ARCH\n",
            "Model Number: 129 with model Theta in generation 0 of 10\n",
            "Model Number: 130 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 131 with model GLM in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 131: GLM\n",
            "Model Number: 132 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 133 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 134 with model MultivariateRegression in generation 0 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 7s 22ms/step - loss: 0.2571\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2383\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2182\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2173\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2061\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2203\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2051\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1988\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1910\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2080\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1885\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1808\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1733\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1745\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1569\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1627\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1479\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1538\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1451\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1216\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1335\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1181\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1324\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1097\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1177\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1131\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1060\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1018\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1056\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1121\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1002\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0925\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1120\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0936\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1012\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1089\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0995\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0944\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0996\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0960\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1001\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1027\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0950\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0948\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0939\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1070\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0921\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0939\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0992\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0899\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0984\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0979\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1009\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0891\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0919\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0883\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0925\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1005\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0953\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1024\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0854\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0938\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0980\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0931\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0925\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0893\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0859\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0873\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0947\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0856\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0942\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0873\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0930\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0948\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0969\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0899\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0933\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0804\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0917\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0928\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0884\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0897\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0929\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0877\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0875\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0887\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0966\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0915\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0848\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0895\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0903\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0903\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0950\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0866\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0959\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0862\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0837\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0979\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0911\n",
            "Model Number: 135 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 136 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 137 with model MultivariateMotif in generation 0 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 138 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 139 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 139: VECM\n",
            "Model Number: 140 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 141 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 142 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 143 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 144 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 145 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 146 with model ETS in generation 0 of 10\n",
            "Model Number: 147 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 148 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 149 with model ETS in generation 0 of 10\n",
            "Model Number: 150 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 150: GLM\n",
            "Model Number: 151 with model GLS in generation 0 of 10\n",
            "Model Number: 152 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 153 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 153: ARDL\n",
            "Model Number: 154 with model GluonTS in generation 0 of 10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1231: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 154: GluonTS\n",
            "Model Number: 155 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 156 with model ARIMA in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 156: ARIMA\n",
            "Model Number: 157 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 158 with model ARIMA in generation 0 of 10\n",
            "Model Number: 159 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 160 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 160: GluonTS\n",
            "Model Number: 161 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 162 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 162: ARCH\n",
            "Model Number: 163 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 163: GLM\n",
            "Model Number: 164 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 165 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 166 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 167 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 168 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 168: VECM\n",
            "Model Number: 169 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 170 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 170: VECM\n",
            "Model Number: 171 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RobustScaler failed on fit') in model 171: GluonTS\n",
            "Model Number: 172 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 173 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 173: ARDL\n",
            "Model Number: 174 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 175 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 176 with model GLM in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1120: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1376: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning:\n",
            "\n",
            "Feature names only support names that are all strings. Got feature names with dtypes: ['Timestamp', 'str']. An error will be raised in 1.2.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 177 with model GLS in generation 0 of 10\n",
            "Model Number: 178 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 178: VAR\n",
            "Model Number: 179 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 180 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 181 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 182 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on inverse') in model 182: UnivariateMotif\n",
            "Model Number: 183 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 183: ARDL\n",
            "New Generation: 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning:\n",
            "\n",
            "The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- weekdayofmonth_1\n",
            "- weekdayofmonth_5\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 184 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 185 with model ETS in generation 1 of 10\n",
            "Model Number: 186 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 187 with model Theta in generation 1 of 10\n",
            "Model Number: 188 with model Theta in generation 1 of 10\n",
            "Model Number: 189 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 190 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 191 with model ARIMA in generation 1 of 10\n",
            "Model Number: 192 with model Theta in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/dbo4ipri.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/itgbcpqs.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=45672', 'data', 'file=/tmp/tmpc_zyl9m1/dbo4ipri.json', 'init=/tmp/tmpc_zyl9m1/itgbcpqs.json', 'output', 'file=/tmp/tmpbk6_jg_1/prophet_model-20220925145024.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:50:24 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:50:24 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 193 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 193: MultivariateRegression\n",
            "Model Number: 194 with model FBProphet in generation 1 of 10\n",
            "Model Number: 195 with model NVAR in generation 1 of 10\n",
            "Model Number: 196 with model ARIMA in generation 1 of 10\n",
            "Model Number: 197 with model LastValueNaive in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model LastValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 197: LastValueNaive\n",
            "Model Number: 198 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 199 with model ARIMA in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/percentile.py:47: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 200 with model GLS in generation 1 of 10\n",
            "Model Number: 201 with model NVAR in generation 1 of 10\n",
            "Model Number: 202 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 203 with model Theta in generation 1 of 10\n",
            "Model Number: 204 with model ETS in generation 1 of 10\n",
            "Model Number: 205 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 206 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 207 with model GLM in generation 1 of 10\n",
            "Model Number: 208 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 209 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 210 with model ARIMA in generation 1 of 10\n",
            "Model Number: 211 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 212 with model GLM in generation 1 of 10\n",
            "Model Number: 213 with model ARIMA in generation 1 of 10\n",
            "Model Number: 214 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 215 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 216 with model LastValueNaive in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model LastValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 216: LastValueNaive\n",
            "Model Number: 217 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 218 with model UnivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/percentile.py:47: RuntimeWarning:\n",
            "\n",
            "All-NaN slice encountered\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 219 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 220 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 221 with model MultivariateRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 222 with model ARIMA in generation 1 of 10\n",
            "Model Number: 223 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 224 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 225 with model MultivariateRegression in generation 1 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 7s 28ms/step - loss: 0.6814\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.5911\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.5248\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4740\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4157\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4462\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4230\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3808\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3830\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3864\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3796\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3868\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3740\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3758\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3776\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3636\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3722\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3820\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3834\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3548\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3649\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3657\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3743\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3683\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3592\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3547\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3545\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3761\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3541\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3576\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3545\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3611\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3572\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3695\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3537\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3566\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3436\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3552\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.3521\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3605\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3483\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3495\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3481\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3540\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3485\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3469\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3506\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3565\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3475\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3484\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3607\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3495\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3620\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3396\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3548\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3410\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3511\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3459\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3488\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3481\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3526\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3477\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3327\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3532\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3373\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3419\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3505\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3410\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3544\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3500\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3471\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3376\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3430\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3492\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3462\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3373\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3533\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3373\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3299\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3477\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3292\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3280\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3249\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3492\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3419\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3283\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3255\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3359\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3167\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3333\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3369\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3225\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3254\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3200\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3302\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3283\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3280\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3107\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3384\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3174\n",
            "Model Number: 226 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 227 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 228 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 229 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 230 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 231 with model GLM in generation 1 of 10\n",
            "Model Number: 232 with model Theta in generation 1 of 10\n",
            "Model Number: 233 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 234 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 235 with model GLS in generation 1 of 10\n",
            "Model Number: 236 with model ARIMA in generation 1 of 10\n",
            "Model Number: 237 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 237: DatepartRegression\n",
            "Model Number: 238 with model MultivariateRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:412: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 239 with model UnivariateMotif in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model UnivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 239: UnivariateMotif\n",
            "Model Number: 240 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 241 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 242 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 243 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 244 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 245 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 246 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 247 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 248 with model Theta in generation 1 of 10\n",
            "Model Number: 249 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 250 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 251 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 252 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 253 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 254 with model ARIMA in generation 1 of 10\n",
            "Model Number: 255 with model GLS in generation 1 of 10\n",
            "Model Number: 256 with model ARIMA in generation 1 of 10\n",
            "Model Number: 257 with model ETS in generation 1 of 10\n",
            "Model Number: 258 with model Theta in generation 1 of 10\n",
            "Model Number: 259 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 260 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 261 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 262 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 263 with model MultivariateRegression in generation 1 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 7s 27ms/step - loss: 158.0318\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 154.8837\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 153.9843\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 153.5690\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 153.2760\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 153.0302\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 152.8059\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 152.5915\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 152.3826\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 152.1767\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 151.9745\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 151.7727\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 151.5723\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 151.3728\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 151.1737\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 150.9746\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 150.7760\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 150.5775\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 150.3791\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 150.1808\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 149.9826\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 149.7845\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 149.5864\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 149.3883\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 149.1902\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 148.9922\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 148.7942\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 148.5961\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 148.3981\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 148.2001\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 148.0021\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 147.8041\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 147.6061\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 147.4081\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 147.2101\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 147.0121\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 146.8141\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 146.6161\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 146.4181\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 146.2201\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 146.0221\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 145.8241\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 145.6261\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 145.4281\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 145.2301\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 145.0321\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 144.8341\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 144.6361\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 144.4381\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 144.2401\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 144.0421\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 143.8441\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 143.6461\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 143.4481\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 143.2501\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 143.0521\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 142.8541\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 142.6561\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 142.4581\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 142.2601\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 142.0621\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 141.8641\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 141.6661\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 141.4681\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 141.2701\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 141.0721\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 140.8741\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 140.6761\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 140.4781\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 140.2802\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 140.0822\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 139.8842\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 139.6862\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 139.4882\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 139.2902\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 139.0922\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 138.8942\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 138.6962\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 138.4982\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 138.3002\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 138.1022\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 137.9042\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 137.7062\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 137.5082\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 137.3102\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 137.1122\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 136.9142\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 136.7162\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 136.5182\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 136.3202\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 136.1222\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 135.9242\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 135.7262\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 135.5282\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 135.3302\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 135.1322\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 134.9342\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 134.7362\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 134.5382\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 134.3402\n",
            "Model Number: 264 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 265 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 266 with model MultivariateMotif in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 266: MultivariateMotif\n",
            "Model Number: 267 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 268 with model ETS in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:412: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 269 with model GLS in generation 1 of 10\n",
            "Model Number: 270 with model ARIMA in generation 1 of 10\n",
            "Model Number: 271 with model ETS in generation 1 of 10\n",
            "Model Number: 272 with model GLS in generation 1 of 10\n",
            "Model Number: 273 with model WindowRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 274 with model DatepartRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 275 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 276 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 277 with model ARIMA in generation 1 of 10\n",
            "Model Number: 278 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 279 with model UnivariateRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 279: UnivariateRegression\n",
            "Model Number: 280 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 281 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 282 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 283 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 284 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 285 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 286 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 287 with model UnivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 288 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/9kkmtu6a.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/m04fokwi.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=31759', 'data', 'file=/tmp/tmpc_zyl9m1/9kkmtu6a.json', 'init=/tmp/tmpc_zyl9m1/m04fokwi.json', 'output', 'file=/tmp/tmp1lp7i5wc/prophet_model-20220925145157.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:51:57 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:51:57 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 289 with model ARIMA in generation 1 of 10\n",
            "Model Number: 290 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 291 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 291: ConstantNaive\n",
            "Model Number: 292 with model MultivariateMotif in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 292: MultivariateMotif\n",
            "Model Number: 293 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 294 with model Theta in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:412: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 295 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 296 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 297 with model GLM in generation 1 of 10\n",
            "Model Number: 298 with model GLS in generation 1 of 10\n",
            "Model Number: 299 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 300 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 301 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 302 with model NVAR in generation 1 of 10\n",
            "Model Number: 303 with model UnivariateRegression in generation 1 of 10\n",
            "New Generation: 2 of 10\n",
            "Model Number: 304 with model ARIMA in generation 2 of 10\n",
            "Model Number: 305 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 306 with model GLS in generation 2 of 10\n",
            "Model Number: 307 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 308 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 309 with model NVAR in generation 2 of 10\n",
            "Model Number: 310 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 311 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 312 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 313 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 314 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 315 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 316 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 317 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 318 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 319 with model Theta in generation 2 of 10\n",
            "Model Number: 320 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 321 with model Theta in generation 2 of 10\n",
            "Model Number: 322 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 323 with model Theta in generation 2 of 10\n",
            "Model Number: 324 with model ARIMA in generation 2 of 10\n",
            "Model Number: 325 with model ARIMA in generation 2 of 10\n",
            "Model Number: 326 with model Theta in generation 2 of 10\n",
            "Model Number: 327 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 328 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 329 with model UnivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 329: UnivariateRegression\n",
            "Model Number: 330 with model ETS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 330: ETS\n",
            "Model Number: 331 with model NVAR in generation 2 of 10\n",
            "Model Number: 332 with model Theta in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 333 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/5663wyis.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/eh8dqce9.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=76167', 'data', 'file=/tmp/tmpc_zyl9m1/5663wyis.json', 'init=/tmp/tmpc_zyl9m1/eh8dqce9.json', 'output', 'file=/tmp/tmp55a7pxhy/prophet_model-20220925145208.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:52:08 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:52:08 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 334 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 335 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 335: MultivariateRegression\n",
            "Model Number: 336 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 337 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 338 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 339 with model ETS in generation 2 of 10\n",
            "Model Number: 340 with model ARIMA in generation 2 of 10\n",
            "Model Number: 341 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 342 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 343 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 344 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 345 with model NVAR in generation 2 of 10\n",
            "Model Number: 346 with model Theta in generation 2 of 10\n",
            "Model Number: 347 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 348 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 349 with model ARIMA in generation 2 of 10\n",
            "Model Number: 350 with model GLM in generation 2 of 10\n",
            "Model Number: 351 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 352 with model FBProphet in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 352: FBProphet\n",
            "Model Number: 353 with model NVAR in generation 2 of 10\n",
            "Model Number: 354 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 354: MultivariateRegression\n",
            "Model Number: 355 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 356 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 357 with model Theta in generation 2 of 10\n",
            "Model Number: 358 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 359 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 360 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 361 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 362 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 363 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 364 with model NVAR in generation 2 of 10\n",
            "Model Number: 365 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 366 with model UnivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 366: UnivariateRegression\n",
            "Model Number: 367 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 368 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 369 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 370 with model ARIMA in generation 2 of 10\n",
            "Model Number: 371 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 372 with model ETS in generation 2 of 10\n",
            "Model Number: 373 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 374 with model Theta in generation 2 of 10\n",
            "Model Number: 375 with model MultivariateRegression in generation 2 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 7s 15ms/step - loss: 0.5281\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3937\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3745\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3817\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3858\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3985\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3822\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3667\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3738\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3776\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3955\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3815\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3802\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3684\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3776\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3668\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3709\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3774\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3901\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3677\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3855\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3757\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3694\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3590\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3570\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3661\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3790\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3658\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3545\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3670\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3505\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3627\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3689\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3471\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3536\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3437\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3513\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3612\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3438\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3466\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3578\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3435\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3354\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3410\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3425\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3295\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3601\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3578\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3354\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3271\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3567\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3131\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3473\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3279\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3239\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3400\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3342\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3310\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3236\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3261\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3269\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3281\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3232\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3172\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3150\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3044\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3313\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3181\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3124\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3172\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3385\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3064\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3161\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3132\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3308\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3187\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3234\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3217\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3108\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3286\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3057\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2995\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3278\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3293\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2927\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2936\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3159\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3198\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3022\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3151\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3029\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3033\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3128\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3136\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3108\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3052\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3083\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2994\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3279\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3093\n",
            "Model Number: 376 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 377 with model MultivariateRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/r0w2tjar.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/lgz3zd84.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=25349', 'data', 'file=/tmp/tmpc_zyl9m1/r0w2tjar.json', 'init=/tmp/tmpc_zyl9m1/lgz3zd84.json', 'output', 'file=/tmp/tmpt6l16x2t/prophet_model-20220925145236.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:52:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:52:36 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 378 with model FBProphet in generation 2 of 10\n",
            "Model Number: 379 with model Theta in generation 2 of 10\n",
            "Model Number: 380 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 381 with model UnivariateMotif in generation 2 of 10\n",
            "Template Eval Error: ValueError('Model UnivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 381: UnivariateMotif\n",
            "Model Number: 382 with model ARIMA in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:412: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 383 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 384 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 384: MultivariateRegression\n",
            "Model Number: 385 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0, tolerance: 0.0\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 386 with model ETS in generation 2 of 10\n",
            "Model Number: 387 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 388 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 389 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 390 with model ARIMA in generation 2 of 10\n",
            "Model Number: 391 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=9.08159e-25): result may not be accurate.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/nzmns22r.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/3m11cb60.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=98625', 'data', 'file=/tmp/tmpc_zyl9m1/nzmns22r.json', 'init=/tmp/tmpc_zyl9m1/3m11cb60.json', 'output', 'file=/tmp/tmpplg_4ewn/prophet_model-20220925145241.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:52:41 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:52:41 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 392 with model Theta in generation 2 of 10\n",
            "Model Number: 393 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 394 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 395 with model ARIMA in generation 2 of 10\n",
            "Model Number: 396 with model WindowRegression in generation 2 of 10\n",
            "No anomalies detected.\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 396: WindowRegression\n",
            "Model Number: 397 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 398 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 399 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 400 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 401 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 402 with model ARIMA in generation 2 of 10\n",
            "Model Number: 403 with model GLS in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 404 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 405 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 406 with model Theta in generation 2 of 10\n",
            "Model Number: 407 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 408 with model GLM in generation 2 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 408: GLM\n",
            "Model Number: 409 with model ARIMA in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 410 with model MultivariateRegression in generation 2 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 6s 26ms/step - loss: 0.1099\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0681\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0735\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0724\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0718\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0729\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0678\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0646\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0680\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0713\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0679\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0700\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0641\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0680\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0642\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0650\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0630\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0656\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0634\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0650\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0621\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0648\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0617\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0641\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0610\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0610\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0616\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0572\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0568\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0573\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0528\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0540\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0534\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0517\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0530\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0457\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0499\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0496\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0433\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0459\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0438\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0466\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0389\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0453\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0427\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0417\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0425\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0422\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0398\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0400\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0417\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0430\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0404\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0373\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0351\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0446\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0451\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0413\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0366\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0390\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0418\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0371\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0373\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0434\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0351\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0437\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0428\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0388\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0415\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0375\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0419\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0363\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0364\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0397\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0415\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0370\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0384\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0439\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0369\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0377\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0412\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0377\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0364\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0431\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0378\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0391\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0381\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0408\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0387\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0372\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0399\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0349\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0411\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0386\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0394\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0380\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0367\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0360\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0411\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0368\n",
            "Model Number: 411 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 412 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 412: UnobservedComponents\n",
            "Model Number: 413 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 414 with model GLM in generation 2 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 414: GLM\n",
            "Model Number: 415 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 416 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 417 with model ConstantNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 417: ConstantNaive\n",
            "Model Number: 418 with model ConstantNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 419 with model GLS in generation 2 of 10\n",
            "Model Number: 420 with model MultivariateMotif in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'PowerTransformer', '1': 'CumSumTransformer', '2': 'Slice'}, 'transformation_params': {'0': {}, '1': {}, '2': {'method': 0.8}}}. fail_on_forecast_nan=True\") in model 420: MultivariateMotif\n",
            "Model Number: 421 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 422 with model NVAR in generation 2 of 10\n",
            "Model Number: 423 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 423: UnobservedComponents\n",
            "New Generation: 3 of 10\n",
            "Model Number: 424 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 425 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 426 with model Theta in generation 3 of 10\n",
            "Model Number: 427 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 427: UnivariateRegression\n",
            "Model Number: 428 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 429 with model GLS in generation 3 of 10\n",
            "Model Number: 430 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 431 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 432 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 433 with model ETS in generation 3 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 434 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 435 with model ARIMA in generation 3 of 10\n",
            "Model Number: 436 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 437 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 5s 54ms/step - loss: 5.9367 - val_loss: 0.9934\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 5.4963 - val_loss: 1.0753\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.8463 - val_loss: 1.1044\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.0876 - val_loss: 0.6564\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 4.2968 - val_loss: 1.7827\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.3636 - val_loss: 2.1112\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.2598 - val_loss: 0.3863\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.3727 - val_loss: 1.1977\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.3285 - val_loss: 1.7260\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.1445 - val_loss: 0.3766\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7681 - val_loss: 0.6625\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.9807 - val_loss: 0.7770\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.0064 - val_loss: 1.4231\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.0707 - val_loss: 0.8465\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.6887 - val_loss: 0.7609\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.6007 - val_loss: 0.4365\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.5634 - val_loss: 0.9543\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.6347 - val_loss: 0.5781\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.4500 - val_loss: 0.5122\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.8650 - val_loss: 0.8935\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 437: DatepartRegression\n",
            "Model Number: 438 with model GLS in generation 3 of 10\n",
            "Model Number: 439 with model ARIMA in generation 3 of 10\n",
            "Model Number: 440 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 441 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 442 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 443 with model Theta in generation 3 of 10\n",
            "Model Number: 444 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 445 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 446 with model GLM in generation 3 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 446: GLM\n",
            "Model Number: 447 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 448 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 449 with model UnobservedComponents in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1231: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 450 with model GLM in generation 3 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 450: GLM\n",
            "Model Number: 451 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 452 with model NVAR in generation 3 of 10\n",
            "Model Number: 453 with model GLS in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 454 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 455 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 456 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 457 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 458 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/t7_syjx7.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 459 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ir0p6b_c.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=48904', 'data', 'file=/tmp/tmpc_zyl9m1/t7_syjx7.json', 'init=/tmp/tmpc_zyl9m1/ir0p6b_c.json', 'output', 'file=/tmp/tmpyqztjf9q/prophet_model-20220925145335.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:53:35 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:53:35 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 460 with model Theta in generation 3 of 10\n",
            "Model Number: 461 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 462 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 463 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 464 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 465 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 2s 3ms/step - loss: 54538027401216.0000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538027401216.0000\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 54538014818304.0000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538019012608.0000\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 54538014818304.0000\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538014818304.0000\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 54538010624000.0000\n",
            "Template Eval Error: ValueError('Must pass 2-d input. shape=(10, 10, 5)') in model 465: DatepartRegression\n",
            "Model Number: 466 with model GLS in generation 3 of 10\n",
            "Model Number: 467 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 468 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 469 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 470 with model ARIMA in generation 3 of 10\n",
            "Model Number: 471 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 472 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 473 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 474 with model LastValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 475 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/egd4q9ai.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/04q0eie8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=18038', 'data', 'file=/tmp/tmpc_zyl9m1/egd4q9ai.json', 'init=/tmp/tmpc_zyl9m1/04q0eie8.json', 'output', 'file=/tmp/tmpkn5hig99/prophet_model-20220925145344.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:53:44 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:53:44 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 476 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: LinAlgError('Matrix is not positive definite') in model 476: MultivariateRegression\n",
            "Model Number: 477 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 478 with model ARIMA in generation 3 of 10\n",
            "Model Number: 479 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 480 with model GLS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 480: GLS\n",
            "Model Number: 481 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 482 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 483 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 484 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 485 with model GLS in generation 3 of 10\n",
            "Model Number: 486 with model LastValueNaive in generation 3 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 487 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/n67geux1.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/1qxx3rkw.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=92221', 'data', 'file=/tmp/tmpc_zyl9m1/n67geux1.json', 'init=/tmp/tmpc_zyl9m1/1qxx3rkw.json', 'output', 'file=/tmp/tmp4xqb6bud/prophet_model-20220925145347.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "14:53:47 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:53:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 488 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 489 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 490 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 491 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 492 with model ETS in generation 3 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 493 with model ARIMA in generation 3 of 10\n",
            "Model Number: 494 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 495 with model ARIMA in generation 3 of 10\n",
            "Model Number: 496 with model GLS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 496: GLS\n",
            "Model Number: 497 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 498 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 499 with model Theta in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 500 with model ARIMA in generation 3 of 10\n",
            "Model Number: 501 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 501: FBProphet\n",
            "Model Number: 502 with model Theta in generation 3 of 10\n",
            "Model Number: 503 with model ETS in generation 3 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 504 with model Theta in generation 3 of 10\n",
            "Model Number: 505 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 506 with model ETS in generation 3 of 10\n",
            "Model Number: 507 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 508 with model Theta in generation 3 of 10\n",
            "Model Number: 509 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 510 with model ETS in generation 3 of 10\n",
            "Model Number: 511 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 512 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 513 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 514 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 515 with model NVAR in generation 3 of 10\n",
            "Template Eval Error: LinAlgError('SVD did not converge') in model 515: NVAR\n",
            "Model Number: 516 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 517 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 518 with model ETS in generation 3 of 10\n",
            "Model Number: 519 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 520 with model ARIMA in generation 3 of 10\n",
            "Model Number: 521 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 521: UnivariateRegression\n",
            "Model Number: 522 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 523 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 524 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 525 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 526 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 527 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 527: MultivariateRegression\n",
            "Model Number: 528 with model ARIMA in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 529 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 530 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 531 with model ETS in generation 3 of 10\n",
            "Model Number: 532 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 533 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 534 with model GLS in generation 3 of 10\n",
            "Template Eval Error: ValueError('zero-size array to reduction operation maximum which has no identity') in model 534: GLS\n",
            "Model Number: 535 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 536 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 537 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 538 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 538: MultivariateRegression\n",
            "Model Number: 539 with model Theta in generation 3 of 10\n",
            "Model Number: 540 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 541 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 542 with model GLM in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/links.py:188: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError('shapes (10,56) and (58,) not aligned: 56 (dim 1) != 58 (dim 0)') in model 542: GLM\n",
            "Model Number: 543 with model AverageValueNaive in generation 3 of 10\n",
            "New Generation: 4 of 10\n",
            "Model Number: 544 with model Theta in generation 4 of 10\n",
            "Model Number: 545 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 545: UnobservedComponents\n",
            "Model Number: 546 with model GLS in generation 4 of 10\n",
            "Model Number: 547 with model GLS in generation 4 of 10\n",
            "Model Number: 548 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 549 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 550 with model ARIMA in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 550: ARIMA\n",
            "Model Number: 551 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 552 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 553 with model Theta in generation 4 of 10\n",
            "Model Number: 554 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 555 with model ARIMA in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 555: ARIMA\n",
            "Model Number: 556 with model Theta in generation 4 of 10\n",
            "Model Number: 557 with model SeasonalNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ptu1wn6i.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/dd4ezep9.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=1180', 'data', 'file=/tmp/tmpc_zyl9m1/ptu1wn6i.json', 'init=/tmp/tmpc_zyl9m1/dd4ezep9.json', 'output', 'file=/tmp/tmptkewd6wh/prophet_model-20220925145405.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:54:05 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 558 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:54:05 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 559 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 560 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 561 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 562 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 563 with model ARIMA in generation 4 of 10\n",
            "Model Number: 564 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 564: DatepartRegression\n",
            "Model Number: 565 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 566 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 567 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 568 with model ARIMA in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'zero', 'transformations': {'0': 'PowerTransformer', '1': 'Detrend', '2': 'SeasonalDifference'}, 'transformation_params': {'0': {}, '1': {'model': 'Linear', 'phi': 1, 'window': None, 'transform_dict': None}, '2': {'lag_1': 7, 'method': 'LastValue'}}}. fail_on_forecast_nan=True\") in model 568: ARIMA\n",
            "Model Number: 569 with model ETS in generation 4 of 10\n",
            "Model Number: 570 with model GLS in generation 4 of 10\n",
            "Model Number: 571 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 572 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 573 with model NVAR in generation 4 of 10\n",
            "Model Number: 574 with model UnivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 574: UnivariateRegression\n",
            "Model Number: 575 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 576 with model NVAR in generation 4 of 10\n",
            "Model Number: 577 with model ARIMA in generation 4 of 10\n",
            "Model Number: 578 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 579 with model Theta in generation 4 of 10\n",
            "Model Number: 580 with model NVAR in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 580: NVAR\n",
            "Model Number: 581 with model Theta in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 581: Theta\n",
            "Model Number: 582 with model ARIMA in generation 4 of 10\n",
            "Model Number: 583 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 584 with model UnivariateMotif in generation 4 of 10\n",
            "Template Eval Error: ValueError('Model UnivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 584: UnivariateMotif\n",
            "Model Number: 585 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 586 with model ETS in generation 4 of 10\n",
            "Model Number: 587 with model Theta in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:412: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 588 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 589 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 590 with model NVAR in generation 4 of 10\n",
            "Model Number: 591 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 592 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 593 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 594 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 595 with model ETS in generation 4 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 596 with model GLM in generation 4 of 10\n",
            "Model Number: 597 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 597: MultivariateRegression\n",
            "Model Number: 598 with model ETS in generation 4 of 10\n",
            "Model Number: 599 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 600 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 601 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 602 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 603 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 604 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 605 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 606 with model ETS in generation 4 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-20 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-23 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-27 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-29 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-30 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2021-12-31 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-03 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-05 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-06 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-10 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-12 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-13 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-14 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-17 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-19 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-20 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-26 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-27 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-01-31 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-02 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-03 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-09 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-10 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-14 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-15 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-16 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-17 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-23 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-02-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-02 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-03 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-09 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-10 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-14 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-15 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-16 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-17 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-23 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-29 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-30 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-03-31 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-05 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-06 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-12 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-13 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-14 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-15 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-19 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-20 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-26 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-27 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-04-29 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-02 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-03 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-05 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-06 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-09 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-10 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-12 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-13 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-16 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-17 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-19 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-20 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-23 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-26 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-27 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-30 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-05-31 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-02 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-03 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-06 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-09 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-10 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-13 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-14 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-15 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-16 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-17 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-20 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-23 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-27 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-29 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-06-30 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-05 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-06 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-12 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-13 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-14 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-15 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-19 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-20 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-21 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-26 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-27 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-28 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-07-29 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-02 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-03 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-04 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-05 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-09 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-10 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-11 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-12 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-15 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-16 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-17 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-18 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-19 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-22 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-23 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-24 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-25 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-26 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-29 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-30 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-08-31 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-01 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-02 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-05 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-06 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-07 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-08 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 2022-09-09 00:00:00 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Template Eval Error: KeyError(Timestamp('2021-12-20 00:00:00', freq='B')) in model 606: ETS\n",
            "Model Number: 607 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 608 with model MultivariateMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 609 with model ConstantNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 609: ConstantNaive\n",
            "Model Number: 610 with model GLM in generation 4 of 10\n",
            "Model Number: 611 with model ARIMA in generation 4 of 10\n",
            "Model Number: 612 with model Theta in generation 4 of 10\n",
            "Model Number: 613 with model ETS in generation 4 of 10\n",
            "Model Number: 614 with model ETS in generation 4 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 615 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 616 with model ETS in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 616: ETS\n",
            "Model Number: 617 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 618 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 619 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 620 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 621 with model Theta in generation 4 of 10\n",
            "Model Number: 622 with model Theta in generation 4 of 10\n",
            "Model Number: 623 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 624 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 625 with model MultivariateRegression in generation 4 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 7s 27ms/step - loss: 10.0269\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 8.3481\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 7.4354\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 7.1705\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 7.0248\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6.9317\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 6.8377\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6.7111\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 6.6653\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6.6177\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 6.5181\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6.4272\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 6.4314\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 6.3031\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6.2160\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 6.1014\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 6.0337\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 5.9323\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.8654\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.7976\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.7202\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.6195\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.6473\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 5.5154\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.4427\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.4128\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.2453\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.2300\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1348\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.0516\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.0272\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.9090\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 4.8546\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9123\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8337\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.6803\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.6076\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.5845\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.5875\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 4.4707\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.4320\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 4.2718\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.2098\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.2925\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9961\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.1333\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.0156\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.0265\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.9544\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.8811\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7808\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7645\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8050\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.7490\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.7835\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7063\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6261\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5685\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6562\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5745\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4530\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.5987\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5449\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.3832\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.5328\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.5346\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.4120\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3505\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3984\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3806\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3991\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.3746\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2627\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.2136\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2930\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.2809\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2899\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4393\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.2731\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1663\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1578\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.2609\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2095\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.2852\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.2092\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2248\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 3.0923\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2062\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2817\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.0775\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.0771\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1054\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.0410\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.0727\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1399\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.0158\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2103\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.0392\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.0524\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 2.9743\n",
            "Model Number: 626 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 627 with model AverageValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/gi7jpun0.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/z2i3f638.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=48325', 'data', 'file=/tmp/tmpc_zyl9m1/gi7jpun0.json', 'init=/tmp/tmpc_zyl9m1/z2i3f638.json', 'output', 'file=/tmp/tmpjxqh9u33/prophet_model-20220925145442.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:54:42 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 628 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:54:42 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 629 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 629: DatepartRegression\n",
            "Model Number: 630 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 631 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 632 with model NVAR in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 633 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/exc7v1e3.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/1u16lznt.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=33458', 'data', 'file=/tmp/tmpc_zyl9m1/exc7v1e3.json', 'init=/tmp/tmpc_zyl9m1/1u16lznt.json', 'output', 'file=/tmp/tmpvkh1gjo2/prophet_model-20220925145444.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:54:44 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:54:44 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/w5qv5sud.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/fi3viui6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=52817', 'data', 'file=/tmp/tmpc_zyl9m1/w5qv5sud.json', 'init=/tmp/tmpc_zyl9m1/fi3viui6.json', 'output', 'file=/tmp/tmpj6_b5t9v/prophet_model-20220925145446.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:54:46 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:54:46 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'zero', 'transformations': {'0': 'PowerTransformer', '1': 'MaxAbsScaler', '2': 'MinMaxScaler'}, 'transformation_params': {'0': {}, '1': {}, '2': {}}}. fail_on_forecast_nan=True\") in model 633: FBProphet\n",
            "Model Number: 634 with model FBProphet in generation 4 of 10\n",
            "Model Number: 635 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 636 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 637 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 638 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 639 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 640 with model Theta in generation 4 of 10\n",
            "Model Number: 641 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 642 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 643 with model ARIMA in generation 4 of 10\n",
            "Model Number: 644 with model GLS in generation 4 of 10\n",
            "Model Number: 645 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 646 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 647 with model ETS in generation 4 of 10\n",
            "Model Number: 648 with model ETS in generation 4 of 10\n",
            "Model Number: 649 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 650 with model NVAR in generation 4 of 10\n",
            "Model Number: 651 with model Theta in generation 4 of 10\n",
            "Model Number: 652 with model ARIMA in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 652: ARIMA\n",
            "Model Number: 653 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 654 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 655 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/te00lchp.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/u_uh1tbu.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=42995', 'data', 'file=/tmp/tmpc_zyl9m1/te00lchp.json', 'init=/tmp/tmpc_zyl9m1/u_uh1tbu.json', 'output', 'file=/tmp/tmprbrlruve/prophet_model-20220925145455.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:54:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:54:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 656 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 657 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 658 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 659 with model ETS in generation 4 of 10\n",
            "Model Number: 660 with model UnivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 660: UnivariateRegression\n",
            "Model Number: 661 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 662 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 663 with model AverageValueNaive in generation 4 of 10\n",
            "New Generation: 5 of 10\n",
            "Model Number: 664 with model ARIMA in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 664: ARIMA\n",
            "Model Number: 665 with model Theta in generation 5 of 10\n",
            "Model Number: 666 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 667 with model LastValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 667: LastValueNaive\n",
            "Model Number: 668 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 669 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 670 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 671 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 672 with model NVAR in generation 5 of 10\n",
            "Model Number: 673 with model NVAR in generation 5 of 10\n",
            "Model Number: 674 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 675 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 676 with model UnivariateMotif in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 676: UnivariateMotif\n",
            "Model Number: 677 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 678 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 679 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 680 with model WindowRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 681 with model DatepartRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 681: DatepartRegression\n",
            "Model Number: 682 with model Theta in generation 5 of 10\n",
            "Model Number: 683 with model GLM in generation 5 of 10\n",
            "Model Number: 684 with model DatepartRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 685 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/b0lco4_o.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/jfztkgve.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=42920', 'data', 'file=/tmp/tmpc_zyl9m1/b0lco4_o.json', 'init=/tmp/tmpc_zyl9m1/jfztkgve.json', 'output', 'file=/tmp/tmpcov9bnrz/prophet_model-20220925145501.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:55:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:55:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 686 with model GLM in generation 5 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 686: GLM\n",
            "Model Number: 687 with model NVAR in generation 5 of 10\n",
            "Model Number: 688 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1231: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 689 with model ETS in generation 5 of 10\n",
            "Model Number: 690 with model ARIMA in generation 5 of 10\n",
            "Model Number: 691 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 692 with model GLS in generation 5 of 10\n",
            "Model Number: 693 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 694 with model ETS in generation 5 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 695 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 696 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 697 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 698 with model Theta in generation 5 of 10\n",
            "Model Number: 699 with model ARIMA in generation 5 of 10\n",
            "Model Number: 700 with model MultivariateMotif in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 700: MultivariateMotif\n",
            "Model Number: 701 with model ARIMA in generation 5 of 10\n",
            "Model Number: 702 with model UnivariateRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 702: UnivariateRegression\n",
            "Model Number: 703 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 704 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 705 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 706 with model ETS in generation 5 of 10\n",
            "Model Number: 707 with model ARIMA in generation 5 of 10\n",
            "Model Number: 708 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 709 with model GLM in generation 5 of 10\n",
            "Model Number: 710 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 711 with model GLS in generation 5 of 10\n",
            "Model Number: 712 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 713 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 714 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 715 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 716 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 717 with model GLS in generation 5 of 10\n",
            "Model Number: 718 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 719 with model Theta in generation 5 of 10\n",
            "Model Number: 720 with model ARIMA in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 720: ARIMA\n",
            "Model Number: 721 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 722 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 723 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 724 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 725 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 726 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 727 with model GLS in generation 5 of 10\n",
            "Model Number: 728 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 729 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 730 with model FBProphet in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 730: FBProphet\n",
            "Model Number: 731 with model GLS in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 732 with model ARIMA in generation 5 of 10\n",
            "Model Number: 733 with model Theta in generation 5 of 10\n",
            "Model Number: 734 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 735 with model Theta in generation 5 of 10\n",
            "Model Number: 736 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 737 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 738 with model LastValueNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 739 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 740 with model GLS in generation 5 of 10\n",
            "Model Number: 741 with model ETS in generation 5 of 10\n",
            "Model Number: 742 with model ETS in generation 5 of 10\n",
            "Model Number: 743 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 744 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 745 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 746 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 747 with model NVAR in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 748 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 749 with model Theta in generation 5 of 10\n",
            "Model Number: 750 with model ETS in generation 5 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 751 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 752 with model Theta in generation 5 of 10\n",
            "Model Number: 753 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 754 with model DatepartRegression in generation 5 of 10\n",
            "[LibLinear][LibLinear][LibLinear]Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 754: DatepartRegression\n",
            "Model Number: 755 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 756 with model DatepartRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 757 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 758 with model GLS in generation 5 of 10\n",
            "Model Number: 759 with model UnivariateRegression in generation 5 of 10\n",
            "New Generation: 6 of 10\n",
            "Model Number: 760 with model UnivariateRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 760: UnivariateRegression\n",
            "Model Number: 761 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 762 with model Theta in generation 6 of 10\n",
            "Model Number: 763 with model ARIMA in generation 6 of 10\n",
            "Model Number: 764 with model GLS in generation 6 of 10\n",
            "Model Number: 765 with model ARIMA in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'zero', 'transformations': {'0': 'PowerTransformer', '1': 'SeasonalDifference'}, 'transformation_params': {'0': {}, '1': {'lag_1': 7, 'method': 'LastValue'}}}. fail_on_forecast_nan=True\") in model 765: ARIMA\n",
            "Model Number: 766 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 766: WindowRegression\n",
            "Model Number: 767 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 768 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 769 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 770 with model Theta in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 771 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 772 with model Theta in generation 6 of 10\n",
            "Model Number: 773 with model NVAR in generation 6 of 10\n",
            "Model Number: 774 with model Theta in generation 6 of 10\n",
            "Model Number: 775 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 776 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 777 with model GLS in generation 6 of 10\n",
            "Model Number: 778 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 779 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 780 with model GLS in generation 6 of 10\n",
            "Model Number: 781 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 782 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 783 with model ARIMA in generation 6 of 10\n",
            "Model Number: 784 with model ETS in generation 6 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 785 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 786 with model ETS in generation 6 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 787 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 788 with model GLS in generation 6 of 10\n",
            "Model Number: 789 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 790 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 791 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 792 with model Theta in generation 6 of 10\n",
            "Model Number: 793 with model AverageValueNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/jocm5p4p.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/a9l7y_7j.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=70836', 'data', 'file=/tmp/tmpc_zyl9m1/jocm5p4p.json', 'init=/tmp/tmpc_zyl9m1/a9l7y_7j.json', 'output', 'file=/tmp/tmpt7dmv90o/prophet_model-20220925145528.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:55:28 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 794 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14:55:28 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 795 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 796 with model GLS in generation 6 of 10\n",
            "Model Number: 797 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 798 with model ConstantNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 798: ConstantNaive\n",
            "Model Number: 799 with model NVAR in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 799: NVAR\n",
            "Model Number: 800 with model MultivariateRegression in generation 6 of 10\n",
            "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 800: MultivariateRegression\n",
            "Model Number: 801 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 802 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 803 with model ARIMA in generation 6 of 10\n",
            "Model Number: 804 with model NVAR in generation 6 of 10\n",
            "Model Number: 805 with model NVAR in generation 6 of 10\n",
            "Model Number: 806 with model ETS in generation 6 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 807 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 808 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 809 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 810 with model ETS in generation 6 of 10\n",
            "Model Number: 811 with model GLS in generation 6 of 10\n",
            "Model Number: 812 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/rhfne3ye.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/nfh6v8o3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=16725', 'data', 'file=/tmp/tmpc_zyl9m1/rhfne3ye.json', 'init=/tmp/tmpc_zyl9m1/nfh6v8o3.json', 'output', 'file=/tmp/tmpycn6f17z/prophet_model-20220925145532.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:55:32 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:55:32 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 813 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 813: DatepartRegression\n",
            "Model Number: 814 with model FBProphet in generation 6 of 10\n",
            "Model Number: 815 with model UnobservedComponents in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 815: UnobservedComponents\n",
            "Model Number: 816 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 817 with model ARIMA in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in multiply\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 818 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 819 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 820 with model Theta in generation 6 of 10\n",
            "Model Number: 821 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 822 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 822: WindowRegression\n",
            "Model Number: 823 with model UnivariateRegression in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 823: UnivariateRegression\n",
            "Model Number: 824 with model ETS in generation 6 of 10\n",
            "Model Number: 825 with model ARIMA in generation 6 of 10\n",
            "Model Number: 826 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 827 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 828 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 829 with model NVAR in generation 6 of 10\n",
            "Model Number: 830 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 831 with model GLS in generation 6 of 10\n",
            "Model Number: 832 with model ARIMA in generation 6 of 10\n",
            "Model Number: 833 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 834 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 834: MultivariateRegression\n",
            "Model Number: 835 with model ARIMA in generation 6 of 10\n",
            "Model Number: 836 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 837 with model GLM in generation 6 of 10\n",
            "Model Number: 838 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 839 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 840 with model ConstantNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 841 with model GLM in generation 6 of 10\n",
            "Model Number: 842 with model Theta in generation 6 of 10\n",
            "Model Number: 843 with model ETS in generation 6 of 10\n",
            "Model Number: 844 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 845 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 846 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 847 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 848 with model Theta in generation 6 of 10\n",
            "Model Number: 849 with model Theta in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 849: Theta\n",
            "Model Number: 850 with model ARIMA in generation 6 of 10\n",
            "Model Number: 851 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 852 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 853 with model ConstantNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 853: ConstantNaive\n",
            "Model Number: 854 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 855 with model MultivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/polyint.py:545: RuntimeWarning:\n",
            "\n",
            "overflow encountered in multiply\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/polyint.py:546: RuntimeWarning:\n",
            "\n",
            "overflow encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/polyint.py:643: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 7 of 10\n",
            "Model Number: 856 with model GLS in generation 7 of 10\n",
            "Model Number: 857 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 858 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/2qrvkawa.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/jhbmnrtb.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=90090', 'data', 'file=/tmp/tmpc_zyl9m1/2qrvkawa.json', 'init=/tmp/tmpc_zyl9m1/jhbmnrtb.json', 'output', 'file=/tmp/tmpmlr5tg7x/prophet_model-20220925145554.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:55:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:55:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 859 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 860 with model GLM in generation 7 of 10\n",
            "Template Eval Error: ValueError('shapes (10,56) and (58,) not aligned: 56 (dim 1) != 58 (dim 0)') in model 860: GLM\n",
            "Model Number: 861 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 861: MultivariateRegression\n",
            "Model Number: 862 with model AverageValueNaive in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 862: AverageValueNaive\n",
            "Model Number: 863 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 864 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 865 with model Theta in generation 7 of 10\n",
            "Model Number: 866 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 867 with model GLS in generation 7 of 10\n",
            "Model Number: 868 with model GLS in generation 7 of 10\n",
            "Model Number: 869 with model Theta in generation 7 of 10\n",
            "Model Number: 870 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 871 with model UnivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 871: UnivariateRegression\n",
            "Model Number: 872 with model ARIMA in generation 7 of 10\n",
            "Model Number: 873 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 874 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 875 with model Theta in generation 7 of 10\n",
            "Model Number: 876 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 877 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 878 with model NVAR in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 879 with model UnivariateRegression in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 879: UnivariateRegression\n",
            "Model Number: 880 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/fp11m5cw.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/7yuopyh3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=66191', 'data', 'file=/tmp/tmpc_zyl9m1/fp11m5cw.json', 'init=/tmp/tmpc_zyl9m1/7yuopyh3.json', 'output', 'file=/tmp/tmpjbar_ejr/prophet_model-20220925145601.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:56:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:56:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 881 with model NVAR in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 881: NVAR\n",
            "Model Number: 882 with model ETS in generation 7 of 10\n",
            "Model Number: 883 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 884 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 885 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 886 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 887 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 887: DatepartRegression\n",
            "Model Number: 888 with model NVAR in generation 7 of 10\n",
            "Model Number: 889 with model ARIMA in generation 7 of 10\n",
            "Model Number: 890 with model GLM in generation 7 of 10\n",
            "Model Number: 891 with model DatepartRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 892 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 893 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 894 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 895 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 896 with model MultivariateMotif in generation 7 of 10\n",
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 896: MultivariateMotif\n",
            "Model Number: 897 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 898 with model Theta in generation 7 of 10\n",
            "Model Number: 899 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 900 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 901 with model Theta in generation 7 of 10\n",
            "Model Number: 902 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 903 with model UnivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 903: UnivariateRegression\n",
            "Model Number: 904 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 905 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 906 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 907 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 908 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 909 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 910 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 910: DatepartRegression\n",
            "Model Number: 911 with model ETS in generation 7 of 10\n",
            "Model Number: 912 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 913 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 914 with model NVAR in generation 7 of 10\n",
            "Model Number: 915 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 916 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 917 with model Theta in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 917: Theta\n",
            "Model Number: 918 with model NVAR in generation 7 of 10\n",
            "Model Number: 919 with model SeasonalNaive in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 919: SeasonalNaive\n",
            "Model Number: 920 with model ETS in generation 7 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 921 with model Theta in generation 7 of 10\n",
            "Model Number: 922 with model NVAR in generation 7 of 10\n",
            "Model Number: 923 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 923: DatepartRegression\n",
            "Model Number: 924 with model Theta in generation 7 of 10\n",
            "Model Number: 925 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 926 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 927 with model GLM in generation 7 of 10\n",
            "Model Number: 928 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 929 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 930 with model GLS in generation 7 of 10\n",
            "Model Number: 931 with model GLS in generation 7 of 10\n",
            "Model Number: 932 with model GLS in generation 7 of 10\n",
            "Model Number: 933 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/3fbfx89_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/xzu9936i.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=75455', 'data', 'file=/tmp/tmpc_zyl9m1/3fbfx89_.json', 'init=/tmp/tmpc_zyl9m1/xzu9936i.json', 'output', 'file=/tmp/tmp1gxehh_c/prophet_model-20220925145611.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:56:11 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:56:11 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 934 with model UnivariateMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 934: UnivariateMotif\n",
            "Model Number: 935 with model Theta in generation 7 of 10\n",
            "Model Number: 936 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 937 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 938 with model ARIMA in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 938: ARIMA\n",
            "Model Number: 939 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:2450: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.313308607365798, tolerance: 16.81372568270892\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 940 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 941 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 942 with model GLS in generation 7 of 10\n",
            "Model Number: 943 with model ARIMA in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 944 with model ARIMA in generation 7 of 10\n",
            "Model Number: 945 with model Theta in generation 7 of 10\n",
            "Model Number: 946 with model UnobservedComponents in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"'shape' elements cannot be negative\") in model 946: UnobservedComponents\n",
            "Model Number: 947 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('X has 56 features, but ExtraTreesRegressor is expecting 58 features as input.') in model 947: DatepartRegression\n",
            "Model Number: 948 with model ARIMA in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning:\n",
            "\n",
            "The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- weekdayofmonth_1\n",
            "- weekdayofmonth_5\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 949 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 950 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 951 with model ARIMA in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 951: ARIMA\n",
            "New Generation: 8 of 10\n",
            "Model Number: 952 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 953 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 954 with model ARIMA in generation 8 of 10\n",
            "Model Number: 955 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 956 with model ARIMA in generation 8 of 10\n",
            "Model Number: 957 with model Theta in generation 8 of 10\n",
            "Model Number: 958 with model NVAR in generation 8 of 10\n",
            "Model Number: 959 with model FBProphet in generation 8 of 10\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 959: FBProphet\n",
            "Model Number: 960 with model Theta in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 960: Theta\n",
            "Model Number: 961 with model ARIMA in generation 8 of 10\n",
            "Model Number: 962 with model GLS in generation 8 of 10\n",
            "Model Number: 963 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 964 with model NVAR in generation 8 of 10\n",
            "Model Number: 965 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 966 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 967 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 968 with model SeasonalNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 968: SeasonalNaive\n",
            "Model Number: 969 with model NVAR in generation 8 of 10\n",
            "Model Number: 970 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 971 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 972 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 973 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 974 with model NVAR in generation 8 of 10\n",
            "Model Number: 975 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 976 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 977 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 978 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 979 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 980 with model ARIMA in generation 8 of 10\n",
            "Model Number: 981 with model Theta in generation 8 of 10\n",
            "Model Number: 982 with model MultivariateMotif in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 982: MultivariateMotif\n",
            "Model Number: 983 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 984 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 985 with model Theta in generation 8 of 10\n",
            "Model Number: 986 with model ARIMA in generation 8 of 10\n",
            "Model Number: 987 with model ETS in generation 8 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 988 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 989 with model ARIMA in generation 8 of 10\n",
            "Model Number: 990 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 991 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 992 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 7s 180ms/step - loss: 161032384.0000 - val_loss: 58966608445440.0000\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 259035520.0000 - val_loss: 29062183518208.0000\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 124480040.0000 - val_loss: 14500431396864.0000\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 102046272.0000 - val_loss: 8642168881152.0000\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 152303776.0000 - val_loss: 2887395835904.0000\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 162074960.0000 - val_loss: 9950582538240.0000\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 186673088.0000 - val_loss: 2171942600704.0000\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 216578848.0000 - val_loss: 11788049448960.0000\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 186774992.0000 - val_loss: 3184240885760.0000\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 171143888.0000 - val_loss: 16281446121472.0000\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 125776320.0000 - val_loss: 6480092725248.0000\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 178849360.0000 - val_loss: 9138783387648.0000\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 94325784.0000 - val_loss: 5652894187520.0000\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 88139072.0000 - val_loss: 14518277111808.0000\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 153401312.0000 - val_loss: 21588130922496.0000\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 144837088.0000 - val_loss: 5300193591296.0000\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 105572024.0000 - val_loss: 6976895451136.0000\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 992: DatepartRegression\n",
            "Model Number: 993 with model ETS in generation 8 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 994 with model LastValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 994: LastValueNaive\n",
            "Model Number: 995 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 996 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 997 with model NVAR in generation 8 of 10\n",
            "Model Number: 998 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 999 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1000 with model SectionalMotif in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1000: SectionalMotif\n",
            "Model Number: 1001 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1002 with model AverageValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 1002: AverageValueNaive\n",
            "Model Number: 1003 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1004 with model Theta in generation 8 of 10\n",
            "Model Number: 1005 with model Theta in generation 8 of 10\n",
            "Model Number: 1006 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1007 with model SectionalMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1008 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1009 with model GLS in generation 8 of 10\n",
            "Model Number: 1010 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1011 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1012 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1013 with model ETS in generation 8 of 10\n",
            "Model Number: 1014 with model GLM in generation 8 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1014: GLM\n",
            "Model Number: 1015 with model GLM in generation 8 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 1015: GLM\n",
            "Model Number: 1016 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:428: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:134: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1017 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1018 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1019 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1020 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1021 with model GLS in generation 8 of 10\n",
            "Model Number: 1022 with model ARIMA in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 1022: ARIMA\n",
            "Model Number: 1023 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 1024 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 1025 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1026 with model MultivariateRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1026: MultivariateRegression\n",
            "Model Number: 1027 with model GLS in generation 8 of 10\n",
            "Model Number: 1028 with model GLS in generation 8 of 10\n",
            "Model Number: 1029 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1030 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1031 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1032 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 1033 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1034 with model GLS in generation 8 of 10\n",
            "Model Number: 1035 with model GLS in generation 8 of 10\n",
            "Model Number: 1036 with model Theta in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/_wbbpmul.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/wgepjx2i.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=5248', 'data', 'file=/tmp/tmpc_zyl9m1/_wbbpmul.json', 'init=/tmp/tmpc_zyl9m1/wgepjx2i.json', 'output', 'file=/tmp/tmptmtglyyx/prophet_model-20220925145646.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:56:46 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:56:46 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1037 with model FBProphet in generation 8 of 10\n",
            "Model Number: 1038 with model NVAR in generation 8 of 10\n",
            "Model Number: 1039 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1040 with model UnivariateRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 1040: UnivariateRegression\n",
            "Model Number: 1041 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 1042 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1043 with model UnivariateRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 1043: UnivariateRegression\n",
            "Model Number: 1044 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1045 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1046 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1047 with model ETS in generation 8 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "New Generation: 9 of 10\n",
            "Model Number: 1048 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1049 with model Theta in generation 9 of 10\n",
            "Model Number: 1050 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1051 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1052 with model GLS in generation 9 of 10\n",
            "Model Number: 1053 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1054 with model GLS in generation 9 of 10\n",
            "Model Number: 1055 with model WindowRegression in generation 9 of 10\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 207ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Model Number: 1056 with model NVAR in generation 9 of 10\n",
            "Model Number: 1057 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1058 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1059 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1060 with model Theta in generation 9 of 10\n",
            "Model Number: 1061 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1062 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1063 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1064 with model GLS in generation 9 of 10\n",
            "Model Number: 1065 with model ETS in generation 9 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 1066 with model ARIMA in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 1066: ARIMA\n",
            "Model Number: 1067 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1068 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1069 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1070 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1071 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1072 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1073 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1074 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1075 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1076 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1077 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1078 with model NVAR in generation 9 of 10\n",
            "Model Number: 1079 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1080 with model NVAR in generation 9 of 10\n",
            "Model Number: 1081 with model NVAR in generation 9 of 10\n",
            "Model Number: 1082 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1083 with model SeasonalNaive in generation 9 of 10\n",
            "Template Eval Error: ValueError('Model SeasonalNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 1083: SeasonalNaive\n",
            "Model Number: 1084 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1085 with model GLM in generation 9 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1085: GLM\n",
            "Model Number: 1086 with model Theta in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/generalized_linear_model.py:798: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:134: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1087 with model MultivariateRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 1087: MultivariateRegression\n",
            "Model Number: 1088 with model NVAR in generation 9 of 10\n",
            "Model Number: 1089 with model ARIMA in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1090 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1091 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1092 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1093 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1094 with model GLS in generation 9 of 10\n",
            "Model Number: 1095 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1096 with model ETS in generation 9 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 1097 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/bjop65oj.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ygsp3l42.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=35665', 'data', 'file=/tmp/tmpc_zyl9m1/bjop65oj.json', 'init=/tmp/tmpc_zyl9m1/ygsp3l42.json', 'output', 'file=/tmp/tmpyjxtbjs7/prophet_model-20220925145722.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "14:57:22 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "14:57:22 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1098 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1099 with model Theta in generation 9 of 10\n",
            "Model Number: 1100 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1101 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1102 with model GLM in generation 9 of 10\n",
            "Model Number: 1103 with model AverageValueNaive in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1104 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1105 with model SectionalMotif in generation 9 of 10\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (16)') in model 1105: SectionalMotif\n",
            "Model Number: 1106 with model GLS in generation 9 of 10\n",
            "Model Number: 1107 with model GLS in generation 9 of 10\n",
            "Model Number: 1108 with model ETS in generation 9 of 10\n",
            "Model Number: 1109 with model ETS in generation 9 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 1110 with model GLM in generation 9 of 10\n",
            "Model Number: 1111 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1112 with model Theta in generation 9 of 10\n",
            "Model Number: 1113 with model ARIMA in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 1113: ARIMA\n",
            "Model Number: 1114 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1115 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1116 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1117 with model Theta in generation 9 of 10\n",
            "Model Number: 1118 with model Theta in generation 9 of 10\n",
            "Model Number: 1119 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1120 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1121 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1122 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1123 with model Theta in generation 9 of 10\n",
            "Model Number: 1124 with model UnivariateMotif in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 1124: UnivariateMotif\n",
            "Model Number: 1125 with model NVAR in generation 9 of 10\n",
            "Model Number: 1126 with model ETS in generation 9 of 10\n",
            "Model Number: 1127 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1128 with model Theta in generation 9 of 10\n",
            "Model Number: 1129 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1130 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1131 with model NVAR in generation 9 of 10\n",
            "Model Number: 1132 with model LastValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 1132: LastValueNaive\n",
            "Model Number: 1133 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1134 with model Theta in generation 9 of 10\n",
            "Model Number: 1135 with model MultivariateRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 1135: MultivariateRegression\n",
            "Model Number: 1136 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1137 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1138 with model UnobservedComponents in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=8.69924e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1138: UnobservedComponents\n",
            "Model Number: 1139 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1140 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1140: DatepartRegression\n",
            "Model Number: 1141 with model ConstantNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1141: ConstantNaive\n",
            "Model Number: 1142 with model NVAR in generation 9 of 10\n",
            "Model Number: 1143 with model LastValueNaive in generation 9 of 10\n",
            "New Generation: 10 of 10\n",
            "Model Number: 1144 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1145 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1145: WindowRegression\n",
            "Model Number: 1146 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1147 with model UnobservedComponents in generation 10 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1148 with model SectionalMotif in generation 10 of 10\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (86)') in model 1148: SectionalMotif\n",
            "Model Number: 1149 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1150 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1151 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1152 with model NVAR in generation 10 of 10\n",
            "Model Number: 1153 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer FastICA failed on fit') in model 1153: WindowRegression\n",
            "Model Number: 1154 with model GLS in generation 10 of 10\n",
            "Model Number: 1155 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1156 with model UnivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:532: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1157 with model ARIMA in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1157: ARIMA\n",
            "Model Number: 1158 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1159 with model NVAR in generation 10 of 10\n",
            "Model Number: 1160 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1161 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1162 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1163 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1164 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1165 with model MultivariateRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1165: MultivariateRegression\n",
            "Model Number: 1166 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1167 with model GLS in generation 10 of 10\n",
            "Model Number: 1168 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1169 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1170 with model Theta in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1170: Theta\n",
            "Model Number: 1171 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1172 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1173 with model NVAR in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 1173: NVAR\n",
            "Model Number: 1174 with model NVAR in generation 10 of 10\n",
            "Model Number: 1175 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1176 with model Theta in generation 10 of 10\n",
            "Model Number: 1177 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1178 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1179 with model NVAR in generation 10 of 10\n",
            "Model Number: 1180 with model ConstantNaive in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1180: ConstantNaive\n",
            "Model Number: 1181 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1182 with model UnivariateRegression in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1182: UnivariateRegression\n",
            "Model Number: 1183 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1184 with model GLS in generation 10 of 10\n",
            "Model Number: 1185 with model Theta in generation 10 of 10\n",
            "Model Number: 1186 with model GLS in generation 10 of 10\n",
            "Model Number: 1187 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1188 with model Theta in generation 10 of 10\n",
            "Model Number: 1189 with model Theta in generation 10 of 10\n",
            "Model Number: 1190 with model NVAR in generation 10 of 10\n",
            "Model Number: 1191 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1192 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1193 with model GLS in generation 10 of 10\n",
            "Model Number: 1194 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1195 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1196 with model NVAR in generation 10 of 10\n",
            "Model Number: 1197 with model GLS in generation 10 of 10\n",
            "Model Number: 1198 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1199 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1200 with model MultivariateRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1200: MultivariateRegression\n",
            "Model Number: 1201 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1201: WindowRegression\n",
            "Model Number: 1202 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1203 with model DatepartRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=5.16494e-25): result may not be accurate.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1204 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1205 with model Theta in generation 10 of 10\n",
            "Model Number: 1206 with model GLM in generation 10 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 1206: GLM\n",
            "Model Number: 1207 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1208 with model ETS in generation 10 of 10\n",
            "Model Number: 1209 with model SeasonalNaive in generation 10 of 10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1231: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Number: 1210 with model Theta in generation 10 of 10\n",
            "Model Number: 1211 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1212 with model MultivariateRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 1212: MultivariateRegression\n",
            "Model Number: 1213 with model MultivariateMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:3253: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1214 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1215 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1216 with model Ensemble in generation 11 of Ensembles\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 202ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Model Number: 1217 with model Ensemble in generation 11 of Ensembles\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 210ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Model Number: 1218 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1219 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1220 with model Ensemble in generation 11 of Ensembles\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 202ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Model Number: 1221 with model Ensemble in generation 11 of Ensembles\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 211ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 86ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Model Number: 1222 with model Ensemble in generation 11 of Ensembles\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 205ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Model Number: 1223 with model Ensemble in generation 11 of Ensembles\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 201ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 9.9613e-04 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 8.9246e-04 - val_loss: 0.0014\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 8.0667e-04 - val_loss: 0.0013\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.5420e-04 - val_loss: 0.0011\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 6.5878e-04 - val_loss: 0.0010\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 6.2191e-04 - val_loss: 9.4484e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 6.0192e-04 - val_loss: 8.6314e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 5.7014e-04 - val_loss: 7.9633e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 5.3268e-04 - val_loss: 7.3644e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 5.0010e-04 - val_loss: 6.7908e-04\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 4.3311e-04 - val_loss: 6.2618e-04\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 4.5376e-04 - val_loss: 5.7721e-04\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 3.5815e-04 - val_loss: 5.2855e-04\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 3.5437e-04 - val_loss: 4.8566e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 3.2922e-04 - val_loss: 4.5026e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 3.2629e-04 - val_loss: 4.1915e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 3.5043e-04 - val_loss: 3.9672e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 2.8647e-04 - val_loss: 3.7191e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.3607e-04 - val_loss: 3.4744e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 2.1203e-04 - val_loss: 3.2418e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 2.6607e-04 - val_loss: 3.0484e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.0955e-04 - val_loss: 2.8576e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 2.0488e-04 - val_loss: 2.7178e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 1.8921e-04 - val_loss: 2.6180e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 2.1050e-04 - val_loss: 2.4953e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 1.8673e-04 - val_loss: 2.4579e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.6192e-04 - val_loss: 2.3928e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.8906e-04 - val_loss: 2.3101e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.5545e-04 - val_loss: 2.2474e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.8762e-04 - val_loss: 2.1497e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 1.6522e-04 - val_loss: 2.0828e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.8247e-04 - val_loss: 2.0422e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.5803e-04 - val_loss: 1.9649e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 1.8151e-04 - val_loss: 1.9357e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.5171e-04 - val_loss: 1.9501e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.6478e-04 - val_loss: 1.9106e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.4833e-04 - val_loss: 1.8824e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 1.5391e-04 - val_loss: 1.8187e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 1.6121e-04 - val_loss: 1.7555e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 1.3860e-04 - val_loss: 1.7344e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.4287e-04 - val_loss: 1.6548e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.2509e-04 - val_loss: 1.6445e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 1.3112e-04 - val_loss: 1.6710e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.2878e-04 - val_loss: 1.5942e-04\n",
            "Validation Round: 1\n",
            "Model Number: 1 of 179 with model Ensemble for Validation 1\n",
            "📈 1 - Ensemble with avg smape 1.74: \n",
            "Model Number: 2 of 179 with model Ensemble for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 207ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "📈 2 - Ensemble with avg smape 1.31: \n",
            "Model Number: 3 of 179 with model Ensemble for Validation 1\n",
            "3 - Ensemble with avg smape 2.41: \n",
            "Model Number: 4 of 179 with model Ensemble for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 198ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "📈 4 - Ensemble with avg smape 1.25: \n",
            "Model Number: 5 of 179 with model Ensemble for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 204ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "5 - Ensemble with avg smape 1.32: \n",
            "Model Number: 6 of 179 with model Ensemble for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 203ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "6 - Ensemble with avg smape 1.33: \n",
            "Model Number: 7 of 179 with model Ensemble for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 199ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "7 - Ensemble with avg smape 1.33: \n",
            "Model Number: 8 of 179 with model Ensemble for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 209ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "8 - Ensemble with avg smape 1.33: \n",
            "Model Number: 9 of 179 with model WindowRegression for Validation 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 205ms/step - loss: 0.0192 - val_loss: 0.0405\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0182 - val_loss: 0.0377\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0167 - val_loss: 0.0352\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0150 - val_loss: 0.0328\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0138 - val_loss: 0.0306\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0133 - val_loss: 0.0286\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0267\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0110 - val_loss: 0.0249\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0103 - val_loss: 0.0233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0088 - val_loss: 0.0218\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0086 - val_loss: 0.0205\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0074 - val_loss: 0.0192\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0073 - val_loss: 0.0181\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0069 - val_loss: 0.0171\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0061 - val_loss: 0.0161\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0058 - val_loss: 0.0152\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0051 - val_loss: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0048 - val_loss: 0.0135\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0046 - val_loss: 0.0127\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0044 - val_loss: 0.0119\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.0106\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0034 - val_loss: 0.0099\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.0031 - val_loss: 0.0093\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0025 - val_loss: 0.0082\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.0077\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 0.0072\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0014 - val_loss: 0.0051\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 9.7979e-04 - val_loss: 0.0035\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0010 - val_loss: 0.0033\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 8.9653e-04 - val_loss: 0.0032\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 9.4345e-04 - val_loss: 0.0030\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 7.7596e-04 - val_loss: 0.0028\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 7.8153e-04 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.7950e-04 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 7.0873e-04 - val_loss: 0.0024\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 8.1756e-04 - val_loss: 0.0023\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 5.7922e-04 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 7.0263e-04 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 6.8128e-04 - val_loss: 0.0019\n",
            "9 - WindowRegression with avg smape 1.29: \n",
            "Model Number: 10 of 179 with model SeasonalNaive for Validation 1\n",
            "10 - SeasonalNaive with avg smape 2.08: \n",
            "Model Number: 11 of 179 with model UnivariateRegression for Validation 1\n",
            "11 - UnivariateRegression with avg smape 2.22: \n",
            "Model Number: 12 of 179 with model UnivariateRegression for Validation 1\n",
            "12 - UnivariateRegression with avg smape 3.73: \n",
            "Model Number: 13 of 179 with model MultivariateMotif for Validation 1\n",
            "13 - MultivariateMotif with avg smape 1.71: \n",
            "Model Number: 14 of 179 with model NVAR for Validation 1\n",
            "14 - NVAR with avg smape 4.36: \n",
            "Model Number: 15 of 179 with model UnivariateRegression for Validation 1\n",
            "15 - UnivariateRegression with avg smape 3.35: \n",
            "Model Number: 16 of 179 with model UnivariateRegression for Validation 1\n",
            "16 - UnivariateRegression with avg smape 3.35: \n",
            "Model Number: 17 of 179 with model Theta for Validation 1\n",
            "17 - Theta with avg smape 9.09: \n",
            "Model Number: 18 of 179 with model Theta for Validation 1\n",
            "18 - Theta with avg smape 9.09: \n",
            "Model Number: 19 of 179 with model MultivariateRegression for Validation 1\n",
            "19 - MultivariateRegression with avg smape 2.72: \n",
            "Model Number: 20 of 179 with model UnivariateRegression for Validation 1\n",
            "20 - UnivariateRegression with avg smape 3.41: \n",
            "Model Number: 21 of 179 with model UnivariateRegression for Validation 1\n",
            "21 - UnivariateRegression with avg smape 3.23: \n",
            "Model Number: 22 of 179 with model SeasonalNaive for Validation 1\n",
            "22 - SeasonalNaive with avg smape 1.52: \n",
            "Model Number: 23 of 179 with model ARIMA for Validation 1\n",
            "23 - ARIMA with avg smape 4.81: \n",
            "Model Number: 24 of 179 with model MultivariateRegression for Validation 1\n",
            "24 - MultivariateRegression with avg smape 1.61: \n",
            "Model Number: 25 of 179 with model ConstantNaive for Validation 1\n",
            "25 - ConstantNaive with avg smape 6.12: \n",
            "Model Number: 26 of 179 with model UnivariateRegression for Validation 1\n",
            "26 - UnivariateRegression with avg smape 3.17: \n",
            "Model Number: 27 of 179 with model UnivariateRegression for Validation 1\n",
            "27 - UnivariateRegression with avg smape 3.55: \n",
            "Model Number: 28 of 179 with model NVAR for Validation 1\n",
            "28 - NVAR with avg smape 3.28: \n",
            "Model Number: 29 of 179 with model NVAR for Validation 1\n",
            "29 - NVAR with avg smape 4.52: \n",
            "Model Number: 30 of 179 with model MultivariateMotif for Validation 1\n",
            "30 - MultivariateMotif with avg smape 2.87: \n",
            "Model Number: 31 of 179 with model MultivariateRegression for Validation 1\n",
            "31 - MultivariateRegression with avg smape 1.61: \n",
            "Model Number: 32 of 179 with model UnivariateRegression for Validation 1\n",
            "32 - UnivariateRegression with avg smape 7.42: \n",
            "Model Number: 33 of 179 with model GLS for Validation 1\n",
            "33 - GLS with avg smape 1.87: \n",
            "Model Number: 34 of 179 with model SeasonalNaive for Validation 1\n",
            "34 - SeasonalNaive with avg smape 3.14: \n",
            "Model Number: 35 of 179 with model MultivariateRegression for Validation 1\n",
            "35 - MultivariateRegression with avg smape 7.85: \n",
            "Model Number: 36 of 179 with model ConstantNaive for Validation 1\n",
            "36 - ConstantNaive with avg smape 6.72: \n",
            "Model Number: 37 of 179 with model ARIMA for Validation 1\n",
            "37 - ARIMA with avg smape 7.85: \n",
            "Model Number: 38 of 179 with model SeasonalNaive for Validation 1\n",
            "38 - SeasonalNaive with avg smape 1.53: \n",
            "Model Number: 39 of 179 with model Theta for Validation 1\n",
            "39 - Theta with avg smape 9.38: \n",
            "Model Number: 40 of 179 with model Theta for Validation 1\n",
            "40 - Theta with avg smape 9.38: \n",
            "Model Number: 41 of 179 with model WindowRegression for Validation 1\n",
            "41 - WindowRegression with avg smape 3.1: \n",
            "Model Number: 42 of 179 with model GLS for Validation 1\n",
            "📈 42 - GLS with avg smape 1.24: \n",
            "Model Number: 43 of 179 with model GLS for Validation 1\n",
            "📈 43 - GLS with avg smape 1.23: \n",
            "Model Number: 44 of 179 with model LastValueNaive for Validation 1\n",
            "44 - LastValueNaive with avg smape 1.43: \n",
            "Model Number: 45 of 179 with model Theta for Validation 1\n",
            "45 - Theta with avg smape 4.42: \n",
            "Model Number: 46 of 179 with model GLS for Validation 1\n",
            "46 - GLS with avg smape 1.31: \n",
            "Model Number: 47 of 179 with model ARIMA for Validation 1\n",
            "47 - ARIMA with avg smape 7.48: \n",
            "Model Number: 48 of 179 with model NVAR for Validation 1\n",
            "48 - NVAR with avg smape 4.5: \n",
            "Model Number: 49 of 179 with model ETS for Validation 1\n",
            "49 - ETS with avg smape 1.78: \n",
            "Model Number: 50 of 179 with model ConstantNaive for Validation 1\n",
            "50 - ConstantNaive with avg smape 6.99: \n",
            "Model Number: 51 of 179 with model ConstantNaive for Validation 1\n",
            "51 - ConstantNaive with avg smape 6.99: \n",
            "Model Number: 52 of 179 with model ConstantNaive for Validation 1\n",
            "52 - ConstantNaive with avg smape 6.99: \n",
            "Model Number: 53 of 179 with model ConstantNaive for Validation 1\n",
            "53 - ConstantNaive with avg smape 6.99: \n",
            "Model Number: 54 of 179 with model ConstantNaive for Validation 1\n",
            "54 - ConstantNaive with avg smape 6.99: \n",
            "Model Number: 55 of 179 with model NVAR for Validation 1\n",
            "55 - NVAR with avg smape 1.34: \n",
            "Model Number: 56 of 179 with model MultivariateRegression for Validation 1\n",
            "56 - MultivariateRegression with avg smape 1.61: \n",
            "Model Number: 57 of 179 with model MultivariateMotif for Validation 1\n",
            "57 - MultivariateMotif with avg smape 1.88: \n",
            "Model Number: 58 of 179 with model DatepartRegression for Validation 1\n",
            "58 - DatepartRegression with avg smape 7.38: \n",
            "Model Number: 59 of 179 with model ARIMA for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 - ARIMA with avg smape 4.55: \n",
            "Model Number: 60 of 179 with model Theta for Validation 1\n",
            "60 - Theta with avg smape 6.75: \n",
            "Model Number: 61 of 179 with model GLS for Validation 1\n",
            "61 - GLS with avg smape 4.79: \n",
            "Model Number: 62 of 179 with model NVAR for Validation 1\n",
            "62 - NVAR with avg smape 1.86: \n",
            "Model Number: 63 of 179 with model GLS for Validation 1\n",
            "63 - GLS with avg smape 4.75: \n",
            "Model Number: 64 of 179 with model GLS for Validation 1\n",
            "64 - GLS with avg smape 4.75: \n",
            "Model Number: 65 of 179 with model GLS for Validation 1\n",
            "65 - GLS with avg smape 4.76: \n",
            "Model Number: 66 of 179 with model Theta for Validation 1\n",
            "66 - Theta with avg smape 6.75: \n",
            "Model Number: 67 of 179 with model Theta for Validation 1\n",
            "67 - Theta with avg smape 6.75: \n",
            "Model Number: 68 of 179 with model Theta for Validation 1\n",
            "68 - Theta with avg smape 8.98: \n",
            "Model Number: 69 of 179 with model ARIMA for Validation 1\n",
            "69 - ARIMA with avg smape 6.95: \n",
            "Model Number: 70 of 179 with model ARIMA for Validation 1\n",
            "70 - ARIMA with avg smape 7.18: \n",
            "Model Number: 71 of 179 with model ARIMA for Validation 1\n",
            "71 - ARIMA with avg smape 1.77: \n",
            "Model Number: 72 of 179 with model ARIMA for Validation 1\n",
            "72 - ARIMA with avg smape 1.85: \n",
            "Model Number: 73 of 179 with model ARIMA for Validation 1\n",
            "73 - ARIMA with avg smape 1.78: \n",
            "Model Number: 74 of 179 with model ConstantNaive for Validation 1\n",
            "74 - ConstantNaive with avg smape 7.31: \n",
            "Model Number: 75 of 179 with model ConstantNaive for Validation 1\n",
            "75 - ConstantNaive with avg smape 6.82: \n",
            "Model Number: 76 of 179 with model LastValueNaive for Validation 1\n",
            "76 - LastValueNaive with avg smape 6.82: \n",
            "Model Number: 77 of 179 with model DatepartRegression for Validation 1\n",
            "77 - DatepartRegression with avg smape 3.66: \n",
            "Model Number: 78 of 179 with model SectionalMotif for Validation 1\n",
            "78 - SectionalMotif with avg smape 1.28: \n",
            "Model Number: 79 of 179 with model AverageValueNaive for Validation 1\n",
            "79 - AverageValueNaive with avg smape 6.7: \n",
            "Model Number: 80 of 179 with model AverageValueNaive for Validation 1\n",
            "80 - AverageValueNaive with avg smape 6.96: \n",
            "Model Number: 81 of 179 with model AverageValueNaive for Validation 1\n",
            "81 - AverageValueNaive with avg smape 6.97: \n",
            "Model Number: 82 of 179 with model LastValueNaive for Validation 1\n",
            "82 - LastValueNaive with avg smape 4.36: \n",
            "Model Number: 83 of 179 with model AverageValueNaive for Validation 1\n",
            "83 - AverageValueNaive with avg smape 4.52: \n",
            "Model Number: 84 of 179 with model MultivariateRegression for Validation 1\n",
            "📈 84 - MultivariateRegression with avg smape 1.2: \n",
            "Model Number: 85 of 179 with model WindowRegression for Validation 1\n",
            "85 - WindowRegression with avg smape 6.83: \n",
            "Model Number: 86 of 179 with model AverageValueNaive for Validation 1\n",
            "86 - AverageValueNaive with avg smape 6.18: \n",
            "Model Number: 87 of 179 with model GLS for Validation 1\n",
            "87 - GLS with avg smape 3.5: \n",
            "Model Number: 88 of 179 with model MultivariateRegression for Validation 1\n",
            "88 - MultivariateRegression with avg smape 1.76: \n",
            "Model Number: 89 of 179 with model NVAR for Validation 1\n",
            "89 - NVAR with avg smape 9.31: \n",
            "Model Number: 90 of 179 with model WindowRegression for Validation 1\n",
            "90 - WindowRegression with avg smape 1.27: \n",
            "Model Number: 91 of 179 with model ETS for Validation 1\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "91 - ETS with avg smape 6.56: \n",
            "Model Number: 92 of 179 with model UnivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92 - UnivariateMotif with avg smape 3.63: \n",
            "Model Number: 93 of 179 with model SeasonalNaive for Validation 1\n",
            "93 - SeasonalNaive with avg smape 8.3: \n",
            "Model Number: 94 of 179 with model SeasonalNaive for Validation 1\n",
            "94 - SeasonalNaive with avg smape 4.5: \n",
            "Model Number: 95 of 179 with model SeasonalNaive for Validation 1\n",
            "95 - SeasonalNaive with avg smape 4.7: \n",
            "Model Number: 96 of 179 with model LastValueNaive for Validation 1\n",
            "96 - LastValueNaive with avg smape 7.5: \n",
            "Model Number: 97 of 179 with model MultivariateRegression for Validation 1\n",
            "97 - MultivariateRegression with avg smape 4.7: \n",
            "Model Number: 98 of 179 with model WindowRegression for Validation 1\n",
            "98 - WindowRegression with avg smape 1.54: \n",
            "Model Number: 99 of 179 with model ETS for Validation 1\n",
            "99 - ETS with avg smape 1.98: \n",
            "Model Number: 100 of 179 with model DatepartRegression for Validation 1\n",
            "100 - DatepartRegression with avg smape 7.31: \n",
            "Model Number: 101 of 179 with model GLM for Validation 1\n",
            "101 - GLM with avg smape 4.39: \n",
            "Model Number: 102 of 179 with model AverageValueNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102 - AverageValueNaive with avg smape 3.81: \n",
            "Model Number: 103 of 179 with model ETS for Validation 1\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "103 - ETS with avg smape 2.18: \n",
            "Model Number: 104 of 179 with model ETS for Validation 1\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "104 - ETS with avg smape 2.18: \n",
            "Model Number: 105 of 179 with model SeasonalNaive for Validation 1\n",
            "105 - SeasonalNaive with avg smape 1.52: \n",
            "Model Number: 106 of 179 with model NVAR for Validation 1\n",
            "106 - NVAR with avg smape 9.42: \n",
            "Model Number: 107 of 179 with model ETS for Validation 1\n",
            "107 - ETS with avg smape 5.63: \n",
            "Model Number: 108 of 179 with model MultivariateMotif for Validation 1\n",
            "108 - MultivariateMotif with avg smape 4.25: \n",
            "Model Number: 109 of 179 with model WindowRegression for Validation 1\n",
            "109 - WindowRegression with avg smape 5.08: \n",
            "Model Number: 110 of 179 with model ETS for Validation 1\n",
            "110 - ETS with avg smape 7.93: \n",
            "Model Number: 111 of 179 with model ETS for Validation 1\n",
            "111 - ETS with avg smape 7.93: \n",
            "Model Number: 112 of 179 with model ETS for Validation 1\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "112 - ETS with avg smape 7.93: \n",
            "Model Number: 113 of 179 with model WindowRegression for Validation 1\n",
            "113 - WindowRegression with avg smape 5.43: \n",
            "Model Number: 114 of 179 with model LastValueNaive for Validation 1\n",
            "114 - LastValueNaive with avg smape 6.82: \n",
            "Model Number: 115 of 179 with model MultivariateRegression for Validation 1\n",
            "115 - MultivariateRegression with avg smape 1.22: \n",
            "Model Number: 116 of 179 with model DatepartRegression for Validation 1\n",
            "116 - DatepartRegression with avg smape 3.55: \n",
            "Model Number: 117 of 179 with model UnobservedComponents for Validation 1\n",
            "117 - UnobservedComponents with avg smape 7.31: \n",
            "Model Number: 118 of 179 with model WindowRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118 - WindowRegression with avg smape 3.47: \n",
            "Model Number: 119 of 179 with model NVAR for Validation 1\n",
            "119 - NVAR with avg smape 5.63: \n",
            "Model Number: 120 of 179 with model LastValueNaive for Validation 1\n",
            "120 - LastValueNaive with avg smape 7.83: \n",
            "Model Number: 121 of 179 with model LastValueNaive for Validation 1\n",
            "121 - LastValueNaive with avg smape 7.83: \n",
            "Model Number: 122 of 179 with model LastValueNaive for Validation 1\n",
            "122 - LastValueNaive with avg smape 9.17: \n",
            "Model Number: 123 of 179 with model WindowRegression for Validation 1\n",
            "123 - WindowRegression with avg smape 8.21: \n",
            "Model Number: 124 of 179 with model AverageValueNaive for Validation 1\n",
            "124 - AverageValueNaive with avg smape 3.26: \n",
            "Model Number: 125 of 179 with model LastValueNaive for Validation 1\n",
            "125 - LastValueNaive with avg smape 7.88: \n",
            "Model Number: 126 of 179 with model DatepartRegression for Validation 1\n",
            "126 - DatepartRegression with avg smape 3.56: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 127 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/3hn6rnql.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/sjdppqlu.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=57216', 'data', 'file=/tmp/tmpc_zyl9m1/3hn6rnql.json', 'init=/tmp/tmpc_zyl9m1/sjdppqlu.json', 'output', 'file=/tmp/tmpixpv3w_t/prophet_model-20220925150349.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:03:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:03:50 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127 - FBProphet with avg smape 7.56: \n",
            "Model Number: 128 of 179 with model AverageValueNaive for Validation 1\n",
            "128 - AverageValueNaive with avg smape 4.47: \n",
            "Model Number: 129 of 179 with model DatepartRegression for Validation 1\n",
            "129 - DatepartRegression with avg smape 5.95: \n",
            "Model Number: 130 of 179 with model AverageValueNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ztlw84ld.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/86fxrwfe.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=97955', 'data', 'file=/tmp/tmpc_zyl9m1/ztlw84ld.json', 'init=/tmp/tmpc_zyl9m1/86fxrwfe.json', 'output', 'file=/tmp/tmpys6k3w1i/prophet_model-20220925150352.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:03:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 - AverageValueNaive with avg smape 1.96: \n",
            "Model Number: 131 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:03:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - FBProphet with avg smape 8.07: \n",
            "Model Number: 132 of 179 with model DatepartRegression for Validation 1\n",
            "132 - DatepartRegression with avg smape 7.45: \n",
            "Model Number: 133 of 179 with model SeasonalNaive for Validation 1\n",
            "133 - SeasonalNaive with avg smape 3.54: \n",
            "Model Number: 134 of 179 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - UnobservedComponents with avg smape 7.56: \n",
            "Model Number: 135 of 179 with model DatepartRegression for Validation 1\n",
            "135 - DatepartRegression with avg smape 18.02: \n",
            "Model Number: 136 of 179 with model UnobservedComponents for Validation 1\n",
            "136 - UnobservedComponents with avg smape 6.82: \n",
            "Model Number: 137 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/l5o_som8.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/6ngk2uxd.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=29120', 'data', 'file=/tmp/tmpc_zyl9m1/l5o_som8.json', 'init=/tmp/tmpc_zyl9m1/6ngk2uxd.json', 'output', 'file=/tmp/tmpqz68y_0r/prophet_model-20220925150354.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:03:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:03:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137 - FBProphet with avg smape 2.85: \n",
            "Model Number: 138 of 179 with model DatepartRegression for Validation 1\n",
            "138 - DatepartRegression with avg smape 7.45: \n",
            "Model Number: 139 of 179 with model UnobservedComponents for Validation 1\n",
            "139 - UnobservedComponents with avg smape 7.83: \n",
            "Model Number: 140 of 179 with model MultivariateMotif for Validation 1\n",
            "140 - MultivariateMotif with avg smape 1.73: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 141 of 179 with model MultivariateMotif for Validation 1\n",
            "141 - MultivariateMotif with avg smape 1.73: \n",
            "Model Number: 142 of 179 with model UnivariateMotif for Validation 1\n",
            "142 - UnivariateMotif with avg smape 3.32: \n",
            "Model Number: 143 of 179 with model UnivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/y9ztmcfs.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/62d8mrrg.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=82367', 'data', 'file=/tmp/tmpc_zyl9m1/y9ztmcfs.json', 'init=/tmp/tmpc_zyl9m1/62d8mrrg.json', 'output', 'file=/tmp/tmpwrucok2m/prophet_model-20220925150356.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143 - UnivariateMotif with avg smape 3.74: \n",
            "Model Number: 144 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:03:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:03:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 - FBProphet with avg smape 1.49: \n",
            "Model Number: 145 of 179 with model MultivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/v9ap8twv.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/vc9krzrq.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=14799', 'data', 'file=/tmp/tmpc_zyl9m1/v9ap8twv.json', 'init=/tmp/tmpc_zyl9m1/vc9krzrq.json', 'output', 'file=/tmp/tmpp6fzwhgp/prophet_model-20220925150359.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:03:59 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 - MultivariateMotif with avg smape 7.96: \n",
            "Model Number: 146 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:03:59 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 - FBProphet with avg smape 8.01: \n",
            "Model Number: 147 of 179 with model UnivariateMotif for Validation 1\n",
            "147 - UnivariateMotif with avg smape 3.27: \n",
            "Model Number: 148 of 179 with model MultivariateMotif for Validation 1\n",
            "148 - MultivariateMotif with avg smape 8.45: \n",
            "Model Number: 149 of 179 with model MultivariateMotif for Validation 1\n",
            "📈 149 - MultivariateMotif with avg smape 1.11: \n",
            "Model Number: 150 of 179 with model UnivariateMotif for Validation 1\n",
            "150 - UnivariateMotif with avg smape 3.87: \n",
            "Model Number: 151 of 179 with model GLM for Validation 1\n",
            "151 - GLM with avg smape 8.38: \n",
            "Model Number: 152 of 179 with model SectionalMotif for Validation 1\n",
            "152 - SectionalMotif with avg smape 2.87: \n",
            "Model Number: 153 of 179 with model UnivariateMotif for Validation 1\n",
            "153 - UnivariateMotif with avg smape 2.61: \n",
            "Model Number: 154 of 179 with model UnivariateMotif for Validation 1\n",
            "154 - UnivariateMotif with avg smape 6.32: \n",
            "Model Number: 155 of 179 with model UnobservedComponents for Validation 1\n",
            "155 - UnobservedComponents with avg smape 4.69: \n",
            "Model Number: 156 of 179 with model UnivariateMotif for Validation 1\n",
            "156 - UnivariateMotif with avg smape 4.61: \n",
            "Model Number: 157 of 179 with model UnobservedComponents for Validation 1\n",
            "157 - UnobservedComponents with avg smape 4.1: \n",
            "Model Number: 158 of 179 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=9.18259e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158 - UnobservedComponents with avg smape 4.73: \n",
            "Model Number: 159 of 179 with model UnobservedComponents for Validation 1\n",
            "159 - UnobservedComponents with avg smape 7.7: \n",
            "Model Number: 160 of 179 with model UnivariateMotif for Validation 1\n",
            "160 - UnivariateMotif with avg smape 2.77: \n",
            "Model Number: 161 of 179 with model UnobservedComponents for Validation 1\n",
            "161 - UnobservedComponents with avg smape 4.28: \n",
            "Model Number: 162 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/z61c68jp.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/tsfb3cdf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=24288', 'data', 'file=/tmp/tmpc_zyl9m1/z61c68jp.json', 'init=/tmp/tmpc_zyl9m1/tsfb3cdf.json', 'output', 'file=/tmp/tmp2rp3031_/prophet_model-20220925150402.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:04:02 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:04:02 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162 - FBProphet with avg smape 4.17: \n",
            "Model Number: 163 of 179 with model SectionalMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/wkry5uo4.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/fci50x70.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=31996', 'data', 'file=/tmp/tmpc_zyl9m1/wkry5uo4.json', 'init=/tmp/tmpc_zyl9m1/fci50x70.json', 'output', 'file=/tmp/tmpjzp7q41c/prophet_model-20220925150403.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:04:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163 - SectionalMotif with avg smape 3.48: \n",
            "Model Number: 164 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:04:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164 - FBProphet with avg smape 3.23: \n",
            "Model Number: 165 of 179 with model GLM for Validation 1\n",
            "165 - GLM with avg smape 7.63: \n",
            "Model Number: 166 of 179 with model GLM for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/links.py:188: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166 - GLM with avg smape 7.56: \n",
            "Model Number: 167 of 179 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/3fvmsesb.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/lm2utzx6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=79172', 'data', 'file=/tmp/tmpc_zyl9m1/3fvmsesb.json', 'init=/tmp/tmpc_zyl9m1/lm2utzx6.json', 'output', 'file=/tmp/tmp7i49qvxu/prophet_model-20220925150405.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:04:05 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:04:05 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/m62y9x2k.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/bw7xe812.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=45749', 'data', 'file=/tmp/tmpc_zyl9m1/m62y9x2k.json', 'init=/tmp/tmpc_zyl9m1/bw7xe812.json', 'output', 'file=/tmp/tmp34h3ri3l/prophet_model-20220925150407.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:04:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:04:07 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167 - FBProphet with avg smape 7.07: \n",
            "Model Number: 168 of 179 with model FBProphet for Validation 1\n",
            "168 - FBProphet with avg smape 2.97: \n",
            "Model Number: 169 of 179 with model SectionalMotif for Validation 1\n",
            "169 - SectionalMotif with avg smape 2.05: \n",
            "Model Number: 170 of 179 with model SectionalMotif for Validation 1\n",
            "170 - SectionalMotif with avg smape 2.05: \n",
            "Model Number: 171 of 179 with model GLM for Validation 1\n",
            "171 - GLM with avg smape 4.43: \n",
            "Model Number: 172 of 179 with model SectionalMotif for Validation 1\n",
            "172 - SectionalMotif with avg smape 6.12: \n",
            "Model Number: 173 of 179 with model SectionalMotif for Validation 1\n",
            "173 - SectionalMotif with avg smape 7.24: \n",
            "Model Number: 174 of 179 with model GLM for Validation 1\n",
            "174 - GLM with avg smape 10.35: \n",
            "Model Number: 175 of 179 with model SectionalMotif for Validation 1\n",
            "175 - SectionalMotif with avg smape 5.6: \n",
            "Model Number: 176 of 179 with model SectionalMotif for Validation 1\n",
            "176 - SectionalMotif with avg smape 2.57: \n",
            "Model Number: 177 of 179 with model GLM for Validation 1\n",
            "177 - GLM with avg smape 2.17: \n",
            "Model Number: 178 of 179 with model GLM for Validation 1\n",
            "178 - GLM with avg smape 5.96: \n",
            "Model Number: 179 of 179 with model GLM for Validation 1\n",
            "179 - GLM with avg smape 6.29: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Round: 2\n",
            "Model Number: 1 of 179 with model Ensemble for Validation 2\n",
            "📈 1 - Ensemble with avg smape 4.32: \n",
            "Model Number: 2 of 179 with model Ensemble for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 192ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "📈 2 - Ensemble with avg smape 3.4: \n",
            "Model Number: 3 of 179 with model Ensemble for Validation 2\n",
            "📈 3 - Ensemble with avg smape 2.45: \n",
            "Model Number: 4 of 179 with model Ensemble for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 285ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "4 - Ensemble with avg smape 3.36: \n",
            "Model Number: 5 of 179 with model Ensemble for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 189ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "5 - Ensemble with avg smape 2.98: \n",
            "Model Number: 6 of 179 with model Ensemble for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 328ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "6 - Ensemble with avg smape 2.99: \n",
            "Model Number: 7 of 179 with model Ensemble for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 196ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "7 - Ensemble with avg smape 2.99: \n",
            "Model Number: 8 of 179 with model Ensemble for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 6s 198ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "8 - Ensemble with avg smape 2.99: \n",
            "Model Number: 9 of 179 with model WindowRegression for Validation 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 188ms/step - loss: 0.0031 - val_loss: 4.2239e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 3.7800e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 3.6389e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0019 - val_loss: 3.8535e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0015 - val_loss: 4.4395e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 5.5970e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0010 - val_loss: 7.1840e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 8.4455e-04 - val_loss: 8.8645e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 6.7293e-04 - val_loss: 0.0010\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 6.6910e-04 - val_loss: 0.0012\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 5.9620e-04 - val_loss: 0.0013\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 5.6481e-04 - val_loss: 0.0013\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 5.6323e-04 - val_loss: 0.0013\n",
            "9 - WindowRegression with avg smape 3.36: \n",
            "Model Number: 10 of 179 with model SeasonalNaive for Validation 2\n",
            "📈 10 - SeasonalNaive with avg smape 2.22: \n",
            "Model Number: 11 of 179 with model UnivariateRegression for Validation 2\n",
            "11 - UnivariateRegression with avg smape 3.5: \n",
            "Model Number: 12 of 179 with model UnivariateRegression for Validation 2\n",
            "12 - UnivariateRegression with avg smape 3.38: \n",
            "Model Number: 13 of 179 with model MultivariateMotif for Validation 2\n",
            "13 - MultivariateMotif with avg smape 3.3: \n",
            "Model Number: 14 of 179 with model NVAR for Validation 2\n",
            "14 - NVAR with avg smape 3.7: \n",
            "Model Number: 15 of 179 with model UnivariateRegression for Validation 2\n",
            "15 - UnivariateRegression with avg smape 3.09: \n",
            "Model Number: 16 of 179 with model UnivariateRegression for Validation 2\n",
            "16 - UnivariateRegression with avg smape 3.09: \n",
            "Model Number: 17 of 179 with model Theta for Validation 2\n",
            "17 - Theta with avg smape 2.69: \n",
            "Model Number: 18 of 179 with model Theta for Validation 2\n",
            "18 - Theta with avg smape 2.69: \n",
            "Model Number: 19 of 179 with model MultivariateRegression for Validation 2\n",
            "19 - MultivariateRegression with avg smape 4.11: \n",
            "Model Number: 20 of 179 with model UnivariateRegression for Validation 2\n",
            "20 - UnivariateRegression with avg smape 3.71: \n",
            "Model Number: 21 of 179 with model UnivariateRegression for Validation 2\n",
            "21 - UnivariateRegression with avg smape 3.73: \n",
            "Model Number: 22 of 179 with model SeasonalNaive for Validation 2\n",
            "22 - SeasonalNaive with avg smape 2.44: \n",
            "Model Number: 23 of 179 with model ARIMA for Validation 2\n",
            "23 - ARIMA with avg smape 5.28: \n",
            "Model Number: 24 of 179 with model MultivariateRegression for Validation 2\n",
            "24 - MultivariateRegression with avg smape 4.01: \n",
            "Model Number: 25 of 179 with model ConstantNaive for Validation 2\n",
            "25 - ConstantNaive with avg smape 3.8: \n",
            "Model Number: 26 of 179 with model UnivariateRegression for Validation 2\n",
            "26 - UnivariateRegression with avg smape 2.84: \n",
            "Model Number: 27 of 179 with model UnivariateRegression for Validation 2\n",
            "27 - UnivariateRegression with avg smape 3.67: \n",
            "Model Number: 28 of 179 with model NVAR for Validation 2\n",
            "28 - NVAR with avg smape 17.81: \n",
            "Model Number: 29 of 179 with model NVAR for Validation 2\n",
            "29 - NVAR with avg smape 14.07: \n",
            "Model Number: 30 of 179 with model MultivariateMotif for Validation 2\n",
            "📈 30 - MultivariateMotif with avg smape 1.96: \n",
            "Model Number: 31 of 179 with model MultivariateRegression for Validation 2\n",
            "31 - MultivariateRegression with avg smape 3.93: \n",
            "Model Number: 32 of 179 with model UnivariateRegression for Validation 2\n",
            "32 - UnivariateRegression with avg smape 8.21: \n",
            "Model Number: 33 of 179 with model GLS for Validation 2\n",
            "33 - GLS with avg smape 4.16: \n",
            "Model Number: 34 of 179 with model SeasonalNaive for Validation 2\n",
            "34 - SeasonalNaive with avg smape 2.49: \n",
            "Model Number: 35 of 179 with model MultivariateRegression for Validation 2\n",
            "35 - MultivariateRegression with avg smape 3.5: \n",
            "Model Number: 36 of 179 with model ConstantNaive for Validation 2\n",
            "36 - ConstantNaive with avg smape 3.32: \n",
            "Model Number: 37 of 179 with model ARIMA for Validation 2\n",
            "37 - ARIMA with avg smape 4.26: \n",
            "Model Number: 38 of 179 with model SeasonalNaive for Validation 2\n",
            "38 - SeasonalNaive with avg smape 2.2: \n",
            "Model Number: 39 of 179 with model Theta for Validation 2\n",
            "39 - Theta with avg smape 2.7: \n",
            "Model Number: 40 of 179 with model Theta for Validation 2\n",
            "40 - Theta with avg smape 2.7: \n",
            "Model Number: 41 of 179 with model WindowRegression for Validation 2\n",
            "41 - WindowRegression with avg smape 3.74: \n",
            "Model Number: 42 of 179 with model GLS for Validation 2\n",
            "42 - GLS with avg smape 4.3: \n",
            "Model Number: 43 of 179 with model GLS for Validation 2\n",
            "43 - GLS with avg smape 4.32: \n",
            "Model Number: 44 of 179 with model LastValueNaive for Validation 2\n",
            "44 - LastValueNaive with avg smape 3.53: \n",
            "Model Number: 45 of 179 with model Theta for Validation 2\n",
            "📈 45 - Theta with avg smape 1.34: \n",
            "Model Number: 46 of 179 with model GLS for Validation 2\n",
            "46 - GLS with avg smape 4.19: \n",
            "Model Number: 47 of 179 with model ARIMA for Validation 2\n",
            "47 - ARIMA with avg smape 3.96: \n",
            "Model Number: 48 of 179 with model NVAR for Validation 2\n",
            "48 - NVAR with avg smape 2.2: \n",
            "Model Number: 49 of 179 with model ETS for Validation 2\n",
            "49 - ETS with avg smape 5.65: \n",
            "Model Number: 50 of 179 with model ConstantNaive for Validation 2\n",
            "50 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 51 of 179 with model ConstantNaive for Validation 2\n",
            "51 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 52 of 179 with model ConstantNaive for Validation 2\n",
            "52 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 53 of 179 with model ConstantNaive for Validation 2\n",
            "53 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 54 of 179 with model ConstantNaive for Validation 2\n",
            "54 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 55 of 179 with model NVAR for Validation 2\n",
            "55 - NVAR with avg smape 4.58: \n",
            "Model Number: 56 of 179 with model MultivariateRegression for Validation 2\n",
            "56 - MultivariateRegression with avg smape 3.91: \n",
            "Model Number: 57 of 179 with model MultivariateMotif for Validation 2\n",
            "57 - MultivariateMotif with avg smape 3.74: \n",
            "Model Number: 58 of 179 with model DatepartRegression for Validation 2\n",
            "58 - DatepartRegression with avg smape 3.85: \n",
            "Model Number: 59 of 179 with model ARIMA for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 - ARIMA with avg smape 5.29: \n",
            "Model Number: 60 of 179 with model Theta for Validation 2\n",
            "60 - Theta with avg smape 3.7: \n",
            "Model Number: 61 of 179 with model GLS for Validation 2\n",
            "61 - GLS with avg smape 2.9: \n",
            "Model Number: 62 of 179 with model NVAR for Validation 2\n",
            "62 - NVAR with avg smape 5.72: \n",
            "Model Number: 63 of 179 with model GLS for Validation 2\n",
            "63 - GLS with avg smape 2.94: \n",
            "Model Number: 64 of 179 with model GLS for Validation 2\n",
            "64 - GLS with avg smape 2.94: \n",
            "Model Number: 65 of 179 with model GLS for Validation 2\n",
            "65 - GLS with avg smape 2.93: \n",
            "Model Number: 66 of 179 with model Theta for Validation 2\n",
            "66 - Theta with avg smape 3.7: \n",
            "Model Number: 67 of 179 with model Theta for Validation 2\n",
            "67 - Theta with avg smape 3.7: \n",
            "Model Number: 68 of 179 with model Theta for Validation 2\n",
            "68 - Theta with avg smape 1.78: \n",
            "Model Number: 69 of 179 with model ARIMA for Validation 2\n",
            "69 - ARIMA with avg smape 3.45: \n",
            "Model Number: 70 of 179 with model ARIMA for Validation 2\n",
            "70 - ARIMA with avg smape 3.24: \n",
            "Model Number: 71 of 179 with model ARIMA for Validation 2\n",
            "71 - ARIMA with avg smape 1.73: \n",
            "Model Number: 72 of 179 with model ARIMA for Validation 2\n",
            "72 - ARIMA with avg smape 2.33: \n",
            "Model Number: 73 of 179 with model ARIMA for Validation 2\n",
            "73 - ARIMA with avg smape 2.42: \n",
            "Model Number: 74 of 179 with model ConstantNaive for Validation 2\n",
            "74 - ConstantNaive with avg smape 2.87: \n",
            "Model Number: 75 of 179 with model ConstantNaive for Validation 2\n",
            "75 - ConstantNaive with avg smape 3.52: \n",
            "Model Number: 76 of 179 with model LastValueNaive for Validation 2\n",
            "76 - LastValueNaive with avg smape 3.52: \n",
            "Model Number: 77 of 179 with model DatepartRegression for Validation 2\n",
            "77 - DatepartRegression with avg smape 3.52: \n",
            "Model Number: 78 of 179 with model SectionalMotif for Validation 2\n",
            "78 - SectionalMotif with avg smape 2.98: \n",
            "Model Number: 79 of 179 with model AverageValueNaive for Validation 2\n",
            "79 - AverageValueNaive with avg smape 3.01: \n",
            "Model Number: 80 of 179 with model AverageValueNaive for Validation 2\n",
            "80 - AverageValueNaive with avg smape 3.51: \n",
            "Model Number: 81 of 179 with model AverageValueNaive for Validation 2\n",
            "81 - AverageValueNaive with avg smape 3.49: \n",
            "Model Number: 82 of 179 with model LastValueNaive for Validation 2\n",
            "82 - LastValueNaive with avg smape 2.59: \n",
            "Model Number: 83 of 179 with model AverageValueNaive for Validation 2\n",
            "83 - AverageValueNaive with avg smape 2.74: \n",
            "Model Number: 84 of 179 with model MultivariateRegression for Validation 2\n",
            "84 - MultivariateRegression with avg smape 1.56: \n",
            "Model Number: 85 of 179 with model WindowRegression for Validation 2\n",
            "85 - WindowRegression with avg smape 3.53: \n",
            "Model Number: 86 of 179 with model AverageValueNaive for Validation 2\n",
            "86 - AverageValueNaive with avg smape 3.32: \n",
            "Model Number: 87 of 179 with model GLS for Validation 2\n",
            "87 - GLS with avg smape 2.46: \n",
            "Model Number: 88 of 179 with model MultivariateRegression for Validation 2\n",
            "88 - MultivariateRegression with avg smape 5.54: \n",
            "Model Number: 89 of 179 with model NVAR for Validation 2\n",
            "89 - NVAR with avg smape 2.42: \n",
            "Model Number: 90 of 179 with model WindowRegression for Validation 2\n",
            "90 - WindowRegression with avg smape 12.22: \n",
            "Model Number: 91 of 179 with model ETS for Validation 2\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "91 - ETS with avg smape 2.45: \n",
            "Model Number: 92 of 179 with model UnivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92 - UnivariateMotif with avg smape 2.84: \n",
            "Model Number: 93 of 179 with model SeasonalNaive for Validation 2\n",
            "93 - SeasonalNaive with avg smape 2.02: \n",
            "Model Number: 94 of 179 with model SeasonalNaive for Validation 2\n",
            "94 - SeasonalNaive with avg smape 1.99: \n",
            "Model Number: 95 of 179 with model SeasonalNaive for Validation 2\n",
            "95 - SeasonalNaive with avg smape 3.13: \n",
            "Model Number: 96 of 179 with model LastValueNaive for Validation 2\n",
            "96 - LastValueNaive with avg smape 1.94: \n",
            "Model Number: 97 of 179 with model MultivariateRegression for Validation 2\n",
            "97 - MultivariateRegression with avg smape 2.16: \n",
            "Model Number: 98 of 179 with model WindowRegression for Validation 2\n",
            "98 - WindowRegression with avg smape 13.2: \n",
            "Model Number: 99 of 179 with model ETS for Validation 2\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "99 - ETS with avg smape 3.68: \n",
            "Model Number: 100 of 179 with model DatepartRegression for Validation 2\n",
            "100 - DatepartRegression with avg smape 4.22: \n",
            "Model Number: 101 of 179 with model GLM for Validation 2\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 101: GLM\n",
            "Model Number: 102 of 179 with model AverageValueNaive for Validation 2\n",
            "102 - AverageValueNaive with avg smape 6.0: \n",
            "Model Number: 103 of 179 with model ETS for Validation 2\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1231: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103 - ETS with avg smape 2.04: \n",
            "Model Number: 104 of 179 with model ETS for Validation 2\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "104 - ETS with avg smape 2.04: \n",
            "Model Number: 105 of 179 with model SeasonalNaive for Validation 2\n",
            "105 - SeasonalNaive with avg smape 2.72: \n",
            "Model Number: 106 of 179 with model NVAR for Validation 2\n",
            "106 - NVAR with avg smape 2.43: \n",
            "Model Number: 107 of 179 with model ETS for Validation 2\n",
            "107 - ETS with avg smape 2.04: \n",
            "Model Number: 108 of 179 with model MultivariateMotif for Validation 2\n",
            "108 - MultivariateMotif with avg smape 1.34: \n",
            "Model Number: 109 of 179 with model WindowRegression for Validation 2\n",
            "109 - WindowRegression with avg smape 2.6: \n",
            "Model Number: 110 of 179 with model ETS for Validation 2\n",
            "110 - ETS with avg smape 1.97: \n",
            "Model Number: 111 of 179 with model ETS for Validation 2\n",
            "111 - ETS with avg smape 1.97: \n",
            "Model Number: 112 of 179 with model ETS for Validation 2\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "112 - ETS with avg smape 1.97: \n",
            "Model Number: 113 of 179 with model WindowRegression for Validation 2\n",
            "113 - WindowRegression with avg smape 11.98: \n",
            "Model Number: 114 of 179 with model LastValueNaive for Validation 2\n",
            "114 - LastValueNaive with avg smape 3.52: \n",
            "Model Number: 115 of 179 with model MultivariateRegression for Validation 2\n",
            "115 - MultivariateRegression with avg smape 4.81: \n",
            "Model Number: 116 of 179 with model DatepartRegression for Validation 2\n",
            "116 - DatepartRegression with avg smape 2.17: \n",
            "Model Number: 117 of 179 with model UnobservedComponents for Validation 2\n",
            "117 - UnobservedComponents with avg smape 2.07: \n",
            "Model Number: 118 of 179 with model WindowRegression for Validation 2\n",
            "118 - WindowRegression with avg smape 11.7: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 119 of 179 with model NVAR for Validation 2\n",
            "119 - NVAR with avg smape 3.16: \n",
            "Model Number: 120 of 179 with model LastValueNaive for Validation 2\n",
            "120 - LastValueNaive with avg smape 1.96: \n",
            "Model Number: 121 of 179 with model LastValueNaive for Validation 2\n",
            "121 - LastValueNaive with avg smape 1.96: \n",
            "Model Number: 122 of 179 with model LastValueNaive for Validation 2\n",
            "122 - LastValueNaive with avg smape 2.44: \n",
            "Model Number: 123 of 179 with model WindowRegression for Validation 2\n",
            "123 - WindowRegression with avg smape 4.99: \n",
            "Model Number: 124 of 179 with model AverageValueNaive for Validation 2\n",
            "124 - AverageValueNaive with avg smape 14.63: \n",
            "Model Number: 125 of 179 with model LastValueNaive for Validation 2\n",
            "125 - LastValueNaive with avg smape 1.97: \n",
            "Model Number: 126 of 179 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 - DatepartRegression with avg smape 3.52: \n",
            "Model Number: 127 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/4zexzc7w.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/_be5vl1w.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=56475', 'data', 'file=/tmp/tmpc_zyl9m1/4zexzc7w.json', 'init=/tmp/tmpc_zyl9m1/_be5vl1w.json', 'output', 'file=/tmp/tmpxs9zd8as/prophet_model-20220925150601.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:06:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127 - FBProphet with avg smape 2.94: \n",
            "Model Number: 128 of 179 with model AverageValueNaive for Validation 2\n",
            "128 - AverageValueNaive with avg smape 3.39: \n",
            "Model Number: 129 of 179 with model DatepartRegression for Validation 2\n",
            "129 - DatepartRegression with avg smape 3.97: \n",
            "Model Number: 130 of 179 with model AverageValueNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/p2abgtog.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/qm4k7dnm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=81990', 'data', 'file=/tmp/tmpc_zyl9m1/p2abgtog.json', 'init=/tmp/tmpc_zyl9m1/qm4k7dnm.json', 'output', 'file=/tmp/tmp01oa8ksv/prophet_model-20220925150603.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 - AverageValueNaive with avg smape 4.03: \n",
            "Model Number: 131 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - FBProphet with avg smape 3.77: \n",
            "Model Number: 132 of 179 with model DatepartRegression for Validation 2\n",
            "132 - DatepartRegression with avg smape 5.84: \n",
            "Model Number: 133 of 179 with model SeasonalNaive for Validation 2\n",
            "133 - SeasonalNaive with avg smape 1.61: \n",
            "Model Number: 134 of 179 with model UnobservedComponents for Validation 2\n",
            "134 - UnobservedComponents with avg smape 2.94: \n",
            "Model Number: 135 of 179 with model DatepartRegression for Validation 2\n",
            "135 - DatepartRegression with avg smape 18.4: \n",
            "Model Number: 136 of 179 with model UnobservedComponents for Validation 2\n",
            "136 - UnobservedComponents with avg smape 3.53: \n",
            "Model Number: 137 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ybrewlck.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/2tk0l6xz.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=57063', 'data', 'file=/tmp/tmpc_zyl9m1/ybrewlck.json', 'init=/tmp/tmpc_zyl9m1/2tk0l6xz.json', 'output', 'file=/tmp/tmphxj6men2/prophet_model-20220925150606.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:06 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137 - FBProphet with avg smape 1.6: \n",
            "Model Number: 138 of 179 with model DatepartRegression for Validation 2\n",
            "138 - DatepartRegression with avg smape 5.84: \n",
            "Model Number: 139 of 179 with model UnobservedComponents for Validation 2\n",
            "139 - UnobservedComponents with avg smape 1.96: \n",
            "Model Number: 140 of 179 with model MultivariateMotif for Validation 2\n",
            "140 - MultivariateMotif with avg smape 4.64: \n",
            "Model Number: 141 of 179 with model MultivariateMotif for Validation 2\n",
            "141 - MultivariateMotif with avg smape 4.64: \n",
            "Model Number: 142 of 179 with model UnivariateMotif for Validation 2\n",
            "142 - UnivariateMotif with avg smape 2.24: \n",
            "Model Number: 143 of 179 with model UnivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/p4m29zqm.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/s4dot7id.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143 - UnivariateMotif with avg smape 2.2: \n",
            "Model Number: 144 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=98259', 'data', 'file=/tmp/tmpc_zyl9m1/p4m29zqm.json', 'init=/tmp/tmpc_zyl9m1/s4dot7id.json', 'output', 'file=/tmp/tmpe93szi9i/prophet_model-20220925150608.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "15:06:08 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Communication error on send\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/6mb0xxh9.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/qv0s9brf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=90715', 'data', 'file=/tmp/tmpc_zyl9m1/6mb0xxh9.json', 'init=/tmp/tmpc_zyl9m1/qv0s9brf.json', 'output', 'file=/tmp/tmpe93szi9i/prophet_model-20220925150608.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 - FBProphet with avg smape 9.65: \n",
            "Model Number: 145 of 179 with model MultivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/0_43i3ef.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/iq4junm5.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=88920', 'data', 'file=/tmp/tmpc_zyl9m1/0_43i3ef.json', 'init=/tmp/tmpc_zyl9m1/iq4junm5.json', 'output', 'file=/tmp/tmplxb49pby/prophet_model-20220925150610.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:11 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 - MultivariateMotif with avg smape 3.83: \n",
            "Model Number: 146 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 - FBProphet with avg smape 3.42: \n",
            "Model Number: 147 of 179 with model UnivariateMotif for Validation 2\n",
            "147 - UnivariateMotif with avg smape 2.79: \n",
            "Model Number: 148 of 179 with model MultivariateMotif for Validation 2\n",
            "148 - MultivariateMotif with avg smape 2.78: \n",
            "Model Number: 149 of 179 with model MultivariateMotif for Validation 2\n",
            "149 - MultivariateMotif with avg smape 5.51: \n",
            "Model Number: 150 of 179 with model UnivariateMotif for Validation 2\n",
            "150 - UnivariateMotif with avg smape 2.82: \n",
            "Model Number: 151 of 179 with model GLM for Validation 2\n",
            "151 - GLM with avg smape 1.89: \n",
            "Model Number: 152 of 179 with model SectionalMotif for Validation 2\n",
            "152 - SectionalMotif with avg smape 12.82: \n",
            "Model Number: 153 of 179 with model UnivariateMotif for Validation 2\n",
            "153 - UnivariateMotif with avg smape 3.26: \n",
            "Model Number: 154 of 179 with model UnivariateMotif for Validation 2\n",
            "154 - UnivariateMotif with avg smape 5.12: \n",
            "Model Number: 155 of 179 with model UnobservedComponents for Validation 2\n",
            "155 - UnobservedComponents with avg smape 2.29: \n",
            "Model Number: 156 of 179 with model UnivariateMotif for Validation 2\n",
            "156 - UnivariateMotif with avg smape 2.56: \n",
            "Model Number: 157 of 179 with model UnobservedComponents for Validation 2\n",
            "157 - UnobservedComponents with avg smape 1.86: \n",
            "Model Number: 158 of 179 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=9.72279e-25): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158 - UnobservedComponents with avg smape 3.82: \n",
            "Model Number: 159 of 179 with model UnobservedComponents for Validation 2\n",
            "159 - UnobservedComponents with avg smape 1.97: \n",
            "Model Number: 160 of 179 with model UnivariateMotif for Validation 2\n",
            "📈 160 - UnivariateMotif with avg smape 1.12: \n",
            "Model Number: 161 of 179 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161 - UnobservedComponents with avg smape 5.46: \n",
            "Model Number: 162 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/j6wsq15g.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/eghigwdm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=4440', 'data', 'file=/tmp/tmpc_zyl9m1/j6wsq15g.json', 'init=/tmp/tmpc_zyl9m1/eghigwdm.json', 'output', 'file=/tmp/tmpec5yvh1a/prophet_model-20220925150613.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:13 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162 - FBProphet with avg smape 17.78: \n",
            "Model Number: 163 of 179 with model SectionalMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/bntjp1p4.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/geg_fbt0.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=47862', 'data', 'file=/tmp/tmpc_zyl9m1/bntjp1p4.json', 'init=/tmp/tmpc_zyl9m1/geg_fbt0.json', 'output', 'file=/tmp/tmplvoojhm4/prophet_model-20220925150615.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:15 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163 - SectionalMotif with avg smape 1.95: \n",
            "Model Number: 164 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:06:15 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "15:06:15 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Communication error on send\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/j8f_v438.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/heed7nm6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=60413', 'data', 'file=/tmp/tmpc_zyl9m1/j8f_v438.json', 'init=/tmp/tmpc_zyl9m1/heed7nm6.json', 'output', 'file=/tmp/tmplvoojhm4/prophet_model-20220925150615.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:06:16 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:16 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164 - FBProphet with avg smape 10.47: \n",
            "Model Number: 165 of 179 with model GLM for Validation 2\n",
            "165 - GLM with avg smape 1.97: \n",
            "Model Number: 166 of 179 with model GLM for Validation 2\n",
            "166 - GLM with avg smape 2.94: \n",
            "Model Number: 167 of 179 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/links.py:188: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/w_hlueld.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/tgvq7znb.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=2847', 'data', 'file=/tmp/tmpc_zyl9m1/w_hlueld.json', 'init=/tmp/tmpc_zyl9m1/tgvq7znb.json', 'output', 'file=/tmp/tmp8udcklkl/prophet_model-20220925150618.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:18 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:18 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/62546tnl.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/dak5sxqq.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=48855', 'data', 'file=/tmp/tmpc_zyl9m1/62546tnl.json', 'init=/tmp/tmpc_zyl9m1/dak5sxqq.json', 'output', 'file=/tmp/tmpr7il4a6m/prophet_model-20220925150620.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:06:20 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:06:20 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167 - FBProphet with avg smape 4.14: \n",
            "Model Number: 168 of 179 with model FBProphet for Validation 2\n",
            "168 - FBProphet with avg smape 1.85: \n",
            "Model Number: 169 of 179 with model SectionalMotif for Validation 2\n",
            "169 - SectionalMotif with avg smape 12.62: \n",
            "Model Number: 170 of 179 with model SectionalMotif for Validation 2\n",
            "170 - SectionalMotif with avg smape 12.62: \n",
            "Model Number: 171 of 179 with model GLM for Validation 2\n",
            "171 - GLM with avg smape 2.06: \n",
            "Model Number: 172 of 179 with model SectionalMotif for Validation 2\n",
            "172 - SectionalMotif with avg smape 3.21: \n",
            "Model Number: 173 of 179 with model SectionalMotif for Validation 2\n",
            "173 - SectionalMotif with avg smape 5.73: \n",
            "Model Number: 174 of 179 with model GLM for Validation 2\n",
            "174 - GLM with avg smape 2.87: \n",
            "Model Number: 175 of 179 with model SectionalMotif for Validation 2\n",
            "175 - SectionalMotif with avg smape 1.55: \n",
            "Model Number: 176 of 179 with model SectionalMotif for Validation 2\n",
            "176 - SectionalMotif with avg smape 7.67: \n",
            "Model Number: 177 of 179 with model GLM for Validation 2\n",
            "177 - GLM with avg smape 6.43: \n",
            "Model Number: 178 of 179 with model GLM for Validation 2\n",
            "178 - GLM with avg smape 17.59: \n",
            "Model Number: 179 of 179 with model GLM for Validation 2\n",
            "179 - GLM with avg smape 17.3: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Round: 3\n",
            "Model Number: 1 of 179 with model Ensemble for Validation 3\n",
            "📈 1 - Ensemble with avg smape 1.96: \n",
            "Model Number: 2 of 179 with model Ensemble for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 6s 245ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "📈 2 - Ensemble with avg smape 1.88: \n",
            "Model Number: 3 of 179 with model Ensemble for Validation 3\n",
            "3 - Ensemble with avg smape 3.01: \n",
            "Model Number: 4 of 179 with model Ensemble for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 244ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "4 - Ensemble with avg smape 1.95: \n",
            "Model Number: 5 of 179 with model Ensemble for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 6s 242ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "5 - Ensemble with avg smape 2.31: \n",
            "Model Number: 6 of 179 with model Ensemble for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 252ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "6 - Ensemble with avg smape 2.32: \n",
            "Model Number: 7 of 179 with model Ensemble for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 6s 248ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "7 - Ensemble with avg smape 2.32: \n",
            "Model Number: 8 of 179 with model Ensemble for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 251ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "8 - Ensemble with avg smape 2.32: \n",
            "Model Number: 9 of 179 with model WindowRegression for Validation 3\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 6s 249ms/step - loss: 0.0065 - val_loss: 4.6057e-04\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0060 - val_loss: 3.6688e-04\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0055 - val_loss: 2.9384e-04\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0046 - val_loss: 2.4185e-04\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0043 - val_loss: 2.1160e-04\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0035 - val_loss: 2.0427e-04\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 2.2024e-04\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0030 - val_loss: 2.5961e-04\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0024 - val_loss: 3.2204e-04\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0020 - val_loss: 4.0482e-04\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0015 - val_loss: 5.0622e-04\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 6.2217e-04\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0013 - val_loss: 7.4867e-04\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 9.1501e-04 - val_loss: 8.7602e-04\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 7.1890e-04 - val_loss: 0.0011\n",
            "📈 9 - WindowRegression with avg smape 1.76: \n",
            "Model Number: 10 of 179 with model SeasonalNaive for Validation 3\n",
            "10 - SeasonalNaive with avg smape 3.21: \n",
            "Model Number: 11 of 179 with model UnivariateRegression for Validation 3\n",
            "11 - UnivariateRegression with avg smape 2.23: \n",
            "Model Number: 12 of 179 with model UnivariateRegression for Validation 3\n",
            "12 - UnivariateRegression with avg smape 2.08: \n",
            "Model Number: 13 of 179 with model MultivariateMotif for Validation 3\n",
            "13 - MultivariateMotif with avg smape 1.99: \n",
            "Model Number: 14 of 179 with model NVAR for Validation 3\n",
            "14 - NVAR with avg smape 2.08: \n",
            "Model Number: 15 of 179 with model UnivariateRegression for Validation 3\n",
            "15 - UnivariateRegression with avg smape 2.26: \n",
            "Model Number: 16 of 179 with model UnivariateRegression for Validation 3\n",
            "16 - UnivariateRegression with avg smape 2.26: \n",
            "Model Number: 17 of 179 with model Theta for Validation 3\n",
            "17 - Theta with avg smape 6.58: \n",
            "Model Number: 18 of 179 with model Theta for Validation 3\n",
            "18 - Theta with avg smape 6.58: \n",
            "Model Number: 19 of 179 with model MultivariateRegression for Validation 3\n",
            "19 - MultivariateRegression with avg smape 2.31: \n",
            "Model Number: 20 of 179 with model UnivariateRegression for Validation 3\n",
            "20 - UnivariateRegression with avg smape 2.18: \n",
            "Model Number: 21 of 179 with model UnivariateRegression for Validation 3\n",
            "21 - UnivariateRegression with avg smape 2.0: \n",
            "Model Number: 22 of 179 with model SeasonalNaive for Validation 3\n",
            "22 - SeasonalNaive with avg smape 2.92: \n",
            "Model Number: 23 of 179 with model ARIMA for Validation 3\n",
            "23 - ARIMA with avg smape 12.18: \n",
            "Model Number: 24 of 179 with model MultivariateRegression for Validation 3\n",
            "24 - MultivariateRegression with avg smape 1.97: \n",
            "Model Number: 25 of 179 with model ConstantNaive for Validation 3\n",
            "25 - ConstantNaive with avg smape 8.13: \n",
            "Model Number: 26 of 179 with model UnivariateRegression for Validation 3\n",
            "26 - UnivariateRegression with avg smape 2.73: \n",
            "Model Number: 27 of 179 with model UnivariateRegression for Validation 3\n",
            "27 - UnivariateRegression with avg smape 1.99: \n",
            "Model Number: 28 of 179 with model NVAR for Validation 3\n",
            "28 - NVAR with avg smape 4.94: \n",
            "Model Number: 29 of 179 with model NVAR for Validation 3\n",
            "📈 29 - NVAR with avg smape 1.37: \n",
            "Model Number: 30 of 179 with model MultivariateMotif for Validation 3\n",
            "30 - MultivariateMotif with avg smape 5.4: \n",
            "Model Number: 31 of 179 with model MultivariateRegression for Validation 3\n",
            "31 - MultivariateRegression with avg smape 2.06: \n",
            "Model Number: 32 of 179 with model UnivariateRegression for Validation 3\n",
            "32 - UnivariateRegression with avg smape 4.18: \n",
            "Model Number: 33 of 179 with model GLS for Validation 3\n",
            "33 - GLS with avg smape 6.63: \n",
            "Model Number: 34 of 179 with model SeasonalNaive for Validation 3\n",
            "34 - SeasonalNaive with avg smape 3.89: \n",
            "Model Number: 35 of 179 with model MultivariateRegression for Validation 3\n",
            "35 - MultivariateRegression with avg smape 8.81: \n",
            "Model Number: 36 of 179 with model ConstantNaive for Validation 3\n",
            "36 - ConstantNaive with avg smape 7.48: \n",
            "Model Number: 37 of 179 with model ARIMA for Validation 3\n",
            "37 - ARIMA with avg smape 11.84: \n",
            "Model Number: 38 of 179 with model SeasonalNaive for Validation 3\n",
            "38 - SeasonalNaive with avg smape 3.42: \n",
            "Model Number: 39 of 179 with model Theta for Validation 3\n",
            "39 - Theta with avg smape 5.68: \n",
            "Model Number: 40 of 179 with model Theta for Validation 3\n",
            "40 - Theta with avg smape 5.68: \n",
            "Model Number: 41 of 179 with model WindowRegression for Validation 3\n",
            "📈 41 - WindowRegression with avg smape 1.0: \n",
            "Model Number: 42 of 179 with model GLS for Validation 3\n",
            "42 - GLS with avg smape 6.73: \n",
            "Model Number: 43 of 179 with model GLS for Validation 3\n",
            "43 - GLS with avg smape 6.75: \n",
            "Model Number: 44 of 179 with model LastValueNaive for Validation 3\n",
            "44 - LastValueNaive with avg smape 2.04: \n",
            "Model Number: 45 of 179 with model Theta for Validation 3\n",
            "45 - Theta with avg smape 2.35: \n",
            "Model Number: 46 of 179 with model GLS for Validation 3\n",
            "46 - GLS with avg smape 6.59: \n",
            "Model Number: 47 of 179 with model ARIMA for Validation 3\n",
            "47 - ARIMA with avg smape 9.5: \n",
            "Model Number: 48 of 179 with model NVAR for Validation 3\n",
            "48 - NVAR with avg smape 7.73: \n",
            "Model Number: 49 of 179 with model ETS for Validation 3\n",
            "49 - ETS with avg smape 4.29: \n",
            "Model Number: 50 of 179 with model ConstantNaive for Validation 3\n",
            "50 - ConstantNaive with avg smape 8.49: \n",
            "Model Number: 51 of 179 with model ConstantNaive for Validation 3\n",
            "51 - ConstantNaive with avg smape 8.49: \n",
            "Model Number: 52 of 179 with model ConstantNaive for Validation 3\n",
            "52 - ConstantNaive with avg smape 8.49: \n",
            "Model Number: 53 of 179 with model ConstantNaive for Validation 3\n",
            "53 - ConstantNaive with avg smape 8.49: \n",
            "Model Number: 54 of 179 with model ConstantNaive for Validation 3\n",
            "54 - ConstantNaive with avg smape 8.49: \n",
            "Model Number: 55 of 179 with model NVAR for Validation 3\n",
            "55 - NVAR with avg smape 2.59: \n",
            "Model Number: 56 of 179 with model MultivariateRegression for Validation 3\n",
            "56 - MultivariateRegression with avg smape 2.04: \n",
            "Model Number: 57 of 179 with model MultivariateMotif for Validation 3\n",
            "57 - MultivariateMotif with avg smape 2.34: \n",
            "Model Number: 58 of 179 with model DatepartRegression for Validation 3\n",
            "58 - DatepartRegression with avg smape 7.86: \n",
            "Model Number: 59 of 179 with model ARIMA for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 - ARIMA with avg smape 11.91: \n",
            "Model Number: 60 of 179 with model Theta for Validation 3\n",
            "60 - Theta with avg smape 8.26: \n",
            "Model Number: 61 of 179 with model GLS for Validation 3\n",
            "61 - GLS with avg smape 7.0: \n",
            "Model Number: 62 of 179 with model NVAR for Validation 3\n",
            "62 - NVAR with avg smape 5.12: \n",
            "Model Number: 63 of 179 with model GLS for Validation 3\n",
            "63 - GLS with avg smape 7.07: \n",
            "Model Number: 64 of 179 with model GLS for Validation 3\n",
            "64 - GLS with avg smape 7.07: \n",
            "Model Number: 65 of 179 with model GLS for Validation 3\n",
            "65 - GLS with avg smape 7.06: \n",
            "Model Number: 66 of 179 with model Theta for Validation 3\n",
            "66 - Theta with avg smape 8.26: \n",
            "Model Number: 67 of 179 with model Theta for Validation 3\n",
            "67 - Theta with avg smape 8.26: \n",
            "Model Number: 68 of 179 with model Theta for Validation 3\n",
            "68 - Theta with avg smape 6.01: \n",
            "Model Number: 69 of 179 with model ARIMA for Validation 3\n",
            "69 - ARIMA with avg smape 9.38: \n",
            "Model Number: 70 of 179 with model ARIMA for Validation 3\n",
            "70 - ARIMA with avg smape 7.67: \n",
            "Model Number: 71 of 179 with model ARIMA for Validation 3\n",
            "71 - ARIMA with avg smape 5.96: \n",
            "Model Number: 72 of 179 with model ARIMA for Validation 3\n",
            "72 - ARIMA with avg smape 7.36: \n",
            "Model Number: 73 of 179 with model ARIMA for Validation 3\n",
            "73 - ARIMA with avg smape 6.88: \n",
            "Model Number: 74 of 179 with model ConstantNaive for Validation 3\n",
            "74 - ConstantNaive with avg smape 6.83: \n",
            "Model Number: 75 of 179 with model ConstantNaive for Validation 3\n",
            "75 - ConstantNaive with avg smape 7.95: \n",
            "Model Number: 76 of 179 with model LastValueNaive for Validation 3\n",
            "76 - LastValueNaive with avg smape 7.95: \n",
            "Model Number: 77 of 179 with model DatepartRegression for Validation 3\n",
            "77 - DatepartRegression with avg smape 7.44: \n",
            "Model Number: 78 of 179 with model SectionalMotif for Validation 3\n",
            "78 - SectionalMotif with avg smape 3.94: \n",
            "Model Number: 79 of 179 with model AverageValueNaive for Validation 3\n",
            "79 - AverageValueNaive with avg smape 8.36: \n",
            "Model Number: 80 of 179 with model AverageValueNaive for Validation 3\n",
            "80 - AverageValueNaive with avg smape 8.48: \n",
            "Model Number: 81 of 179 with model AverageValueNaive for Validation 3\n",
            "81 - AverageValueNaive with avg smape 8.46: \n",
            "Model Number: 82 of 179 with model LastValueNaive for Validation 3\n",
            "82 - LastValueNaive with avg smape 6.27: \n",
            "Model Number: 83 of 179 with model AverageValueNaive for Validation 3\n",
            "83 - AverageValueNaive with avg smape 1.11: \n",
            "Model Number: 84 of 179 with model MultivariateRegression for Validation 3\n",
            "84 - MultivariateRegression with avg smape 5.1: \n",
            "Model Number: 85 of 179 with model WindowRegression for Validation 3\n",
            "85 - WindowRegression with avg smape 10.66: \n",
            "Model Number: 86 of 179 with model AverageValueNaive for Validation 3\n",
            "86 - AverageValueNaive with avg smape 9.68: \n",
            "Model Number: 87 of 179 with model GLS for Validation 3\n",
            "87 - GLS with avg smape 4.44: \n",
            "Model Number: 88 of 179 with model MultivariateRegression for Validation 3\n",
            "88 - MultivariateRegression with avg smape 4.34: \n",
            "Model Number: 89 of 179 with model NVAR for Validation 3\n",
            "89 - NVAR with avg smape 5.57: \n",
            "Model Number: 90 of 179 with model WindowRegression for Validation 3\n",
            "90 - WindowRegression with avg smape 13.24: \n",
            "Model Number: 91 of 179 with model ETS for Validation 3\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "91 - ETS with avg smape 7.28: \n",
            "Model Number: 92 of 179 with model UnivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92 - UnivariateMotif with avg smape 5.89: \n",
            "Model Number: 93 of 179 with model SeasonalNaive for Validation 3\n",
            "93 - SeasonalNaive with avg smape 7.19: \n",
            "Model Number: 94 of 179 with model SeasonalNaive for Validation 3\n",
            "94 - SeasonalNaive with avg smape 4.13: \n",
            "Model Number: 95 of 179 with model SeasonalNaive for Validation 3\n",
            "95 - SeasonalNaive with avg smape 3.05: \n",
            "Model Number: 96 of 179 with model LastValueNaive for Validation 3\n",
            "96 - LastValueNaive with avg smape 6.0: \n",
            "Model Number: 97 of 179 with model MultivariateRegression for Validation 3\n",
            "97 - MultivariateRegression with avg smape 1.67: \n",
            "Model Number: 98 of 179 with model WindowRegression for Validation 3\n",
            "98 - WindowRegression with avg smape 13.51: \n",
            "Model Number: 99 of 179 with model ETS for Validation 3\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "99 - ETS with avg smape 2.13: \n",
            "Model Number: 100 of 179 with model DatepartRegression for Validation 3\n",
            "100 - DatepartRegression with avg smape 8.57: \n",
            "Model Number: 101 of 179 with model GLM for Validation 3\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 101: GLM\n",
            "Model Number: 102 of 179 with model AverageValueNaive for Validation 3\n",
            "102 - AverageValueNaive with avg smape 7.46: \n",
            "Model Number: 103 of 179 with model ETS for Validation 3\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1231: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103 - ETS with avg smape 4.02: \n",
            "Model Number: 104 of 179 with model ETS for Validation 3\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "104 - ETS with avg smape 4.02: \n",
            "Model Number: 105 of 179 with model SeasonalNaive for Validation 3\n",
            "105 - SeasonalNaive with avg smape 2.99: \n",
            "Model Number: 106 of 179 with model NVAR for Validation 3\n",
            "106 - NVAR with avg smape 4.45: \n",
            "Model Number: 107 of 179 with model ETS for Validation 3\n",
            "107 - ETS with avg smape 6.48: \n",
            "Model Number: 108 of 179 with model MultivariateMotif for Validation 3\n",
            "108 - MultivariateMotif with avg smape 4.33: \n",
            "Model Number: 109 of 179 with model WindowRegression for Validation 3\n",
            "109 - WindowRegression with avg smape 1.17: \n",
            "Model Number: 110 of 179 with model ETS for Validation 3\n",
            "110 - ETS with avg smape 5.23: \n",
            "Model Number: 111 of 179 with model ETS for Validation 3\n",
            "111 - ETS with avg smape 5.23: \n",
            "Model Number: 112 of 179 with model ETS for Validation 3\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "112 - ETS with avg smape 5.23: \n",
            "Model Number: 113 of 179 with model WindowRegression for Validation 3\n",
            "113 - WindowRegression with avg smape 11.96: \n",
            "Model Number: 114 of 179 with model LastValueNaive for Validation 3\n",
            "114 - LastValueNaive with avg smape 7.95: \n",
            "Model Number: 115 of 179 with model MultivariateRegression for Validation 3\n",
            "115 - MultivariateRegression with avg smape 6.25: \n",
            "Model Number: 116 of 179 with model DatepartRegression for Validation 3\n",
            "116 - DatepartRegression with avg smape 3.9: \n",
            "Model Number: 117 of 179 with model UnobservedComponents for Validation 3\n",
            "117 - UnobservedComponents with avg smape 6.21: \n",
            "Model Number: 118 of 179 with model WindowRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118 - WindowRegression with avg smape 12.35: \n",
            "Model Number: 119 of 179 with model NVAR for Validation 3\n",
            "119 - NVAR with avg smape 5.28: \n",
            "Model Number: 120 of 179 with model LastValueNaive for Validation 3\n",
            "120 - LastValueNaive with avg smape 5.18: \n",
            "Model Number: 121 of 179 with model LastValueNaive for Validation 3\n",
            "121 - LastValueNaive with avg smape 5.18: \n",
            "Model Number: 122 of 179 with model LastValueNaive for Validation 3\n",
            "122 - LastValueNaive with avg smape 4.96: \n",
            "Model Number: 123 of 179 with model WindowRegression for Validation 3\n",
            "123 - WindowRegression with avg smape 9.77: \n",
            "Model Number: 124 of 179 with model AverageValueNaive for Validation 3\n",
            "124 - AverageValueNaive with avg smape 14.45: \n",
            "Model Number: 125 of 179 with model LastValueNaive for Validation 3\n",
            "125 - LastValueNaive with avg smape 5.13: \n",
            "Model Number: 126 of 179 with model DatepartRegression for Validation 3\n",
            "126 - DatepartRegression with avg smape 18.41: \n",
            "Model Number: 127 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/4azjnvqo.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/ydgceqb3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=27927', 'data', 'file=/tmp/tmpc_zyl9m1/4azjnvqo.json', 'init=/tmp/tmpc_zyl9m1/ydgceqb3.json', 'output', 'file=/tmp/tmpqfykek3w/prophet_model-20220925150832.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:08:32 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:33 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127 - FBProphet with avg smape 6.56: \n",
            "Model Number: 128 of 179 with model AverageValueNaive for Validation 3\n",
            "128 - AverageValueNaive with avg smape 2.72: \n",
            "Model Number: 129 of 179 with model DatepartRegression for Validation 3\n",
            "129 - DatepartRegression with avg smape 1.06: \n",
            "Model Number: 130 of 179 with model AverageValueNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/j4twaov8.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/yiuoy17g.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=92113', 'data', 'file=/tmp/tmpc_zyl9m1/j4twaov8.json', 'init=/tmp/tmpc_zyl9m1/yiuoy17g.json', 'output', 'file=/tmp/tmpayki9_1e/prophet_model-20220925150835.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:35 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 - AverageValueNaive with avg smape 1.93: \n",
            "Model Number: 131 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:08:35 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - FBProphet with avg smape 5.68: \n",
            "Model Number: 132 of 179 with model DatepartRegression for Validation 3\n",
            "132 - DatepartRegression with avg smape 9.02: \n",
            "Model Number: 133 of 179 with model SeasonalNaive for Validation 3\n",
            "133 - SeasonalNaive with avg smape 3.31: \n",
            "Model Number: 134 of 179 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - UnobservedComponents with avg smape 6.56: \n",
            "Model Number: 135 of 179 with model DatepartRegression for Validation 3\n",
            "135 - DatepartRegression with avg smape 21.34: \n",
            "Model Number: 136 of 179 with model UnobservedComponents for Validation 3\n",
            "136 - UnobservedComponents with avg smape 7.99: \n",
            "Model Number: 137 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/mwkrj1w_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/83wsg38d.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=39432', 'data', 'file=/tmp/tmpc_zyl9m1/mwkrj1w_.json', 'init=/tmp/tmpc_zyl9m1/83wsg38d.json', 'output', 'file=/tmp/tmpyeidv86b/prophet_model-20220925150837.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:37 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137 - FBProphet with avg smape 3.23: \n",
            "Model Number: 138 of 179 with model DatepartRegression for Validation 3\n",
            "138 - DatepartRegression with avg smape 9.01: \n",
            "Model Number: 139 of 179 with model UnobservedComponents for Validation 3\n",
            "139 - UnobservedComponents with avg smape 5.18: \n",
            "Model Number: 140 of 179 with model MultivariateMotif for Validation 3\n",
            "140 - MultivariateMotif with avg smape 1.09: \n",
            "Model Number: 141 of 179 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141 - MultivariateMotif with avg smape 1.09: \n",
            "Model Number: 142 of 179 with model UnivariateMotif for Validation 3\n",
            "142 - UnivariateMotif with avg smape 3.5: \n",
            "Model Number: 143 of 179 with model UnivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/_x_1j_8p.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/6dzowpq3.json\n",
            "DEBUG:cmdstanpy:idx 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143 - UnivariateMotif with avg smape 5.05: \n",
            "Model Number: 144 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=4090', 'data', 'file=/tmp/tmpc_zyl9m1/_x_1j_8p.json', 'init=/tmp/tmpc_zyl9m1/6dzowpq3.json', 'output', 'file=/tmp/tmpkqwcq_m8/prophet_model-20220925150840.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:40 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:40 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "15:08:40 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Communication error on send\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/y17aqzzn.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/5t2e5mc7.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=90116', 'data', 'file=/tmp/tmpc_zyl9m1/y17aqzzn.json', 'init=/tmp/tmpc_zyl9m1/5t2e5mc7.json', 'output', 'file=/tmp/tmpkqwcq_m8/prophet_model-20220925150840.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:08:40 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:40 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 - FBProphet with avg smape 9.95: \n",
            "Model Number: 145 of 179 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/rtx4h7lm.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/nni9poac.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=44248', 'data', 'file=/tmp/tmpc_zyl9m1/rtx4h7lm.json', 'init=/tmp/tmpc_zyl9m1/nni9poac.json', 'output', 'file=/tmp/tmpjar5pfia/prophet_model-20220925150842.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:42 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 - MultivariateMotif with avg smape 6.73: \n",
            "Model Number: 146 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:08:42 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 - FBProphet with avg smape 6.78: \n",
            "Model Number: 147 of 179 with model UnivariateMotif for Validation 3\n",
            "147 - UnivariateMotif with avg smape 5.46: \n",
            "Model Number: 148 of 179 with model MultivariateMotif for Validation 3\n",
            "148 - MultivariateMotif with avg smape 8.17: \n",
            "Model Number: 149 of 179 with model MultivariateMotif for Validation 3\n",
            "149 - MultivariateMotif with avg smape 4.01: \n",
            "Model Number: 150 of 179 with model UnivariateMotif for Validation 3\n",
            "150 - UnivariateMotif with avg smape 1.36: \n",
            "Model Number: 151 of 179 with model GLM for Validation 3\n",
            "151 - GLM with avg smape 5.34: \n",
            "Model Number: 152 of 179 with model SectionalMotif for Validation 3\n",
            "152 - SectionalMotif with avg smape 11.06: \n",
            "Model Number: 153 of 179 with model UnivariateMotif for Validation 3\n",
            "📈 153 - UnivariateMotif with avg smape 0.85: \n",
            "Model Number: 154 of 179 with model UnivariateMotif for Validation 3\n",
            "154 - UnivariateMotif with avg smape 8.2: \n",
            "Model Number: 155 of 179 with model UnobservedComponents for Validation 3\n",
            "155 - UnobservedComponents with avg smape 2.38: \n",
            "Model Number: 156 of 179 with model UnivariateMotif for Validation 3\n",
            "156 - UnivariateMotif with avg smape 2.81: \n",
            "Model Number: 157 of 179 with model UnobservedComponents for Validation 3\n",
            "157 - UnobservedComponents with avg smape 5.23: \n",
            "Model Number: 158 of 179 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=1.03305e-24): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158 - UnobservedComponents with avg smape 2.78: \n",
            "Model Number: 159 of 179 with model UnobservedComponents for Validation 3\n",
            "159 - UnobservedComponents with avg smape 5.8: \n",
            "Model Number: 160 of 179 with model UnivariateMotif for Validation 3\n",
            "160 - UnivariateMotif with avg smape 1.54: \n",
            "Model Number: 161 of 179 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161 - UnobservedComponents with avg smape 2.72: \n",
            "Model Number: 162 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/i1etzuxx.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/oyt6x9g1.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=77294', 'data', 'file=/tmp/tmpc_zyl9m1/i1etzuxx.json', 'init=/tmp/tmpc_zyl9m1/oyt6x9g1.json', 'output', 'file=/tmp/tmphevijsly/prophet_model-20220925150845.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:45 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:45 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162 - FBProphet with avg smape 16.65: \n",
            "Model Number: 163 of 179 with model SectionalMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/tao2r2je.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/xmejd6g6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=66086', 'data', 'file=/tmp/tmpc_zyl9m1/tao2r2je.json', 'init=/tmp/tmpc_zyl9m1/xmejd6g6.json', 'output', 'file=/tmp/tmphlrt7125/prophet_model-20220925150847.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:47 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163 - SectionalMotif with avg smape 4.73: \n",
            "Model Number: 164 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:08:47 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "15:08:47 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\n",
            "ERROR:cmdstanpy:Chain [1] error: error during processing Communication error on send\n",
            "WARNING:prophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/v7i_k3f_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/5n8tfh4r.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=31791', 'data', 'file=/tmp/tmpc_zyl9m1/v7i_k3f_.json', 'init=/tmp/tmpc_zyl9m1/5n8tfh4r.json', 'output', 'file=/tmp/tmphlrt7125/prophet_model-20220925150847.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "15:08:47 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164 - FBProphet with avg smape 12.47: \n",
            "Model Number: 165 of 179 with model GLM for Validation 3\n",
            "165 - GLM with avg smape 5.78: \n",
            "Model Number: 166 of 179 with model GLM for Validation 3\n",
            "166 - GLM with avg smape 6.56: \n",
            "Model Number: 167 of 179 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/5gmuzhal.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/2zs9ekh3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=51037', 'data', 'file=/tmp/tmpc_zyl9m1/5gmuzhal.json', 'init=/tmp/tmpc_zyl9m1/2zs9ekh3.json', 'output', 'file=/tmp/tmp135kbpoj/prophet_model-20220925150849.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:49 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/pbej2d8q.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc_zyl9m1/a6gi4v_8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=39932', 'data', 'file=/tmp/tmpc_zyl9m1/pbej2d8q.json', 'init=/tmp/tmpc_zyl9m1/a6gi4v_8.json', 'output', 'file=/tmp/tmpr__y3rul/prophet_model-20220925150851.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "15:08:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "15:08:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167 - FBProphet with avg smape 1.82: \n",
            "Model Number: 168 of 179 with model FBProphet for Validation 3\n",
            "168 - FBProphet with avg smape 1.25: \n",
            "Model Number: 169 of 179 with model SectionalMotif for Validation 3\n",
            "169 - SectionalMotif with avg smape 10.01: \n",
            "Model Number: 170 of 179 with model SectionalMotif for Validation 3\n",
            "170 - SectionalMotif with avg smape 10.01: \n",
            "Model Number: 171 of 179 with model GLM for Validation 3\n",
            "171 - GLM with avg smape 2.94: \n",
            "Model Number: 172 of 179 with model SectionalMotif for Validation 3\n",
            "172 - SectionalMotif with avg smape 1.67: \n",
            "Model Number: 173 of 179 with model SectionalMotif for Validation 3\n",
            "173 - SectionalMotif with avg smape 10.01: \n",
            "Model Number: 174 of 179 with model GLM for Validation 3\n",
            "174 - GLM with avg smape 6.48: \n",
            "Model Number: 175 of 179 with model SectionalMotif for Validation 3\n",
            "175 - SectionalMotif with avg smape 13.06: \n",
            "Model Number: 176 of 179 with model SectionalMotif for Validation 3\n",
            "176 - SectionalMotif with avg smape 11.27: \n",
            "Model Number: 177 of 179 with model GLM for Validation 3\n",
            "177 - GLM with avg smape 4.06: \n",
            "Model Number: 178 of 179 with model GLM for Validation 3\n",
            "178 - GLM with avg smape 17.71: \n",
            "Model Number: 179 of 179 with model GLM for Validation 3\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 179: GLM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1444: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in log\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict()\n",
        "forecast = prediction.forecast\n",
        "print(\"Stock Price Prediction of Apple\")\n",
        "print(forecast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrZKPvAgHwPQ",
        "outputId": "e525cf46-65e9-444b-ff76-b06a330c7428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 9s 193ms/step - loss: 0.0118 - val_loss: 0.0071\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0108 - val_loss: 0.0064\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0098 - val_loss: 0.0057\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.0089 - val_loss: 0.0051\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0085 - val_loss: 0.0046\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0073 - val_loss: 0.0041\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.0070 - val_loss: 0.0037\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0065 - val_loss: 0.0033\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0056 - val_loss: 0.0030\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0053 - val_loss: 0.0027\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0047 - val_loss: 0.0025\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.0044 - val_loss: 0.0022\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0041 - val_loss: 0.0020\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0018\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0034 - val_loss: 0.0016\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0015\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.0013\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0012\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0011\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0023 - val_loss: 9.6513e-04\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.0021 - val_loss: 8.6612e-04\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0019 - val_loss: 7.7507e-04\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0018 - val_loss: 6.9281e-04\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.0017 - val_loss: 6.1857e-04\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.0016 - val_loss: 5.5023e-04\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 4.9101e-04\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 4.4111e-04\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0012 - val_loss: 3.9687e-04\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.5713e-04\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 9.7376e-04 - val_loss: 3.2154e-04\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 9.2018e-04 - val_loss: 2.9220e-04\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 8.8260e-04 - val_loss: 2.6809e-04\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 7.7913e-04 - val_loss: 2.4689e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 6.8099e-04 - val_loss: 2.3054e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 7.3715e-04 - val_loss: 2.1539e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 6.4935e-04 - val_loss: 2.0159e-04\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 5.2199e-04 - val_loss: 1.8929e-04\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 5.3632e-04 - val_loss: 1.8024e-04\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 5.7531e-04 - val_loss: 1.7102e-04\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 4.8711e-04 - val_loss: 1.6265e-04\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 4.5150e-04 - val_loss: 1.5703e-04\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 4.1239e-04 - val_loss: 1.5269e-04\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 3.5805e-04 - val_loss: 1.4967e-04\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 3.9224e-04 - val_loss: 1.4530e-04\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 4.2262e-04 - val_loss: 1.4226e-04\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 3.8839e-04 - val_loss: 1.3993e-04\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 3.1221e-04 - val_loss: 1.3642e-04\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 3.2983e-04 - val_loss: 1.3505e-04\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 3.4941e-04 - val_loss: 1.3163e-04\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 3.4000e-04 - val_loss: 1.3100e-04\n",
            "Stock Price Prediction of Apple\n",
            "                 Close\n",
            "2022-09-26  148.086065\n",
            "2022-09-27  146.853919\n",
            "2022-09-28  151.234905\n",
            "2022-09-29  153.962136\n",
            "2022-09-30  151.162302\n",
            "2022-10-03  150.501751\n",
            "2022-10-04  148.648003\n",
            "2022-10-05  146.419327\n",
            "2022-10-06  145.524782\n",
            "2022-10-07  150.140773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast[\"Close\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNAHAjCbNpJb",
        "outputId": "83c184d2-df8f-40ac-e940-24001dceafa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022-09-26    148.086065\n",
              "2022-09-27    146.853919\n",
              "2022-09-28    151.234905\n",
              "2022-09-29    153.962136\n",
              "2022-09-30    151.162302\n",
              "2022-10-03    150.501751\n",
              "2022-10-04    148.648003\n",
              "2022-10-05    146.419327\n",
              "2022-10-06    145.524782\n",
              "2022-10-07    150.140773\n",
              "Freq: B, Name: Close, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pMS71O7iOq4q",
        "outputId": "1497299d-fa1c-41ec-d7fb-593a22b0afdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Close\n",
              "2022-09-26  148.086065\n",
              "2022-09-27  146.853919\n",
              "2022-09-28  151.234905\n",
              "2022-09-29  153.962136\n",
              "2022-09-30  151.162302\n",
              "2022-10-03  150.501751\n",
              "2022-10-04  148.648003\n",
              "2022-10-05  146.419327\n",
              "2022-10-06  145.524782\n",
              "2022-10-07  150.140773"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a67e083-fddb-4056-8177-3a41dd7186ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-09-26</th>\n",
              "      <td>148.086065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-27</th>\n",
              "      <td>146.853919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-28</th>\n",
              "      <td>151.234905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-29</th>\n",
              "      <td>153.962136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>151.162302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-03</th>\n",
              "      <td>150.501751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-04</th>\n",
              "      <td>148.648003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-05</th>\n",
              "      <td>146.419327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-06</th>\n",
              "      <td>145.524782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-07</th>\n",
              "      <td>150.140773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a67e083-fddb-4056-8177-3a41dd7186ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a67e083-fddb-4056-8177-3a41dd7186ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a67e083-fddb-4056-8177-3a41dd7186ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast.reset_index(inplace=True)\n",
        "forecast.rename(columns={\"index\":\"Date\"},inplace=True)"
      ],
      "metadata": {
        "id": "nJd85jMxPYsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "REpMr3jyPefe",
        "outputId": "5dc91765-1775-408d-d738-23dbae428bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   level_0       Date       Close\n",
              "0        0 2022-09-26  148.086065\n",
              "1        1 2022-09-27  146.853919\n",
              "2        2 2022-09-28  151.234905\n",
              "3        3 2022-09-29  153.962136\n",
              "4        4 2022-09-30  151.162302\n",
              "5        5 2022-10-03  150.501751\n",
              "6        6 2022-10-04  148.648003\n",
              "7        7 2022-10-05  146.419327\n",
              "8        8 2022-10-06  145.524782\n",
              "9        9 2022-10-07  150.140773"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0772e98f-5bdf-411c-bb03-64a33e1a6bf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2022-09-26</td>\n",
              "      <td>148.086065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2022-09-27</td>\n",
              "      <td>146.853919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-09-28</td>\n",
              "      <td>151.234905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2022-09-29</td>\n",
              "      <td>153.962136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2022-09-30</td>\n",
              "      <td>151.162302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-03</td>\n",
              "      <td>150.501751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2022-10-04</td>\n",
              "      <td>148.648003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2022-10-05</td>\n",
              "      <td>146.419327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>2022-10-06</td>\n",
              "      <td>145.524782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2022-10-07</td>\n",
              "      <td>150.140773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0772e98f-5bdf-411c-bb03-64a33e1a6bf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0772e98f-5bdf-411c-bb03-64a33e1a6bf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0772e98f-5bdf-411c-bb03-64a33e1a6bf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(data[\"Date\"],data[\"Close\"])\n",
        "plt.plot(forecast[\"Date\"],forecast[\"Close\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "r0IvWCLHMn3K",
        "outputId": "b1ffdd04-a2d4-419f-ce49-c2eb0ab05fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbfc2d53250>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bMjxHUTM9ob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}